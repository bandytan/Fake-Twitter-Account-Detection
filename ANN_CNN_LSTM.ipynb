{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## ANN + CNN + LSTM\n",
    "train a neural network that combines categorical/numerical attributes with images and text data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/twitter_data_train_multiclass.csv')\n",
    "test_df = pd.read_csv('data/twitter_data_test_multiclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "train_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']] = scaler.fit_transform(train_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']])\n",
    "test_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']] = scaler.transform(test_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_base = \"../new batch profile pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all image pathnames from base\n",
    "# list to store files\n",
    "res = []\n",
    "res2 = []\n",
    "\n",
    "# Iterate directory\n",
    "for path in os.listdir(faces_base):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(faces_base, path)):\n",
    "        res.append(faces_base + path)\n",
    "        res2.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dict2 = {}\n",
    "test_img_dict2 = {}\n",
    "train_img2 = []\n",
    "test_img2 = []\n",
    "for i in range(len(res)):\n",
    "    pic = res[i]\n",
    "    id_name = re.match(r\"[^\\/\\\\]+(?=\\.png|\\.jpg)\", res2[i]).group(0)\n",
    "    try:\n",
    "        img = cv2.imread(pic)\n",
    "        if img is None:\n",
    "            print(\"none\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (75, 75))\n",
    "        if int(id_name) in list(train_df['id']):\n",
    "            train_img_dict2[int(id_name)] = img \n",
    "            train_img2.append(img)\n",
    "        elif int(id_name) in list(test_df['id']):\n",
    "            test_img_dict2[int(id_name)] = img\n",
    "            test_img2.append(img)\n",
    "        #img.close()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df2 = pd.DataFrame(train_img_dict2.items(), columns = ['id', 'img'])  \n",
    "test_img_df2 = pd.DataFrame(test_img_dict2.items(), columns = ['id', 'img'])  \n",
    "train_df_with_img2 = pd.merge(train_img_df2, train_df, on='id')\n",
    "test_df_with_img2 = pd.merge(test_img_df2, test_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Unnamed: 0', 'screen_name', 'url', 'profile_image_url', 'description',\n",
    "           'id', 'name', 'account_type', 'tweets_list', 'tweets_list_processed',\n",
    "          'description_processed', 'protected', 'verified', 'account_type_multi', \n",
    "          'profile_use_background_image', 'profile_background_tile']\n",
    "\n",
    "x_train, y_train = train_df.drop(to_drop, axis=1), train_df['account_type_multi']\n",
    "x_test, y_test = test_df.drop(to_drop, axis=1), test_df['account_type_multi']"
   ]
  },
  {
   "source": [
    "### Model training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_df_with_img2.drop(to_drop, axis=1), train_df_with_img2['account_type_multi']\n",
    "x_test, y_test = test_df_with_img2.drop(to_drop, axis=1), test_df_with_img2['account_type_multi']\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_img, x_train_attr = np.stack(x_train['img']) / 255.0, x_train.drop('img', axis=1)\n",
    "x_val_img, x_val_attr = np.stack(x_val['img']) / 255.0, x_val.drop('img', axis=1)\n",
    "x_test_img, x_test_attr = np.stack(x_test['img']) / 255.0, x_test.drop('img', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann():\n",
    "    ann_model = Sequential()\n",
    "    ann_model.add(Dense(64, activation = 'relu', input_dim = 222))\n",
    "    ann_model.add(Dropout(.1))\n",
    "    ann_model.add(Dense(128, activation='relu'))\n",
    "    return ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():    \n",
    "    base_model = InceptionV3(input_shape = (75, 75, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(70, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(50, activation='softmax')(x)\n",
    "    cnn_model = Model(base_model.input, x)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = create_ann()\n",
    "cnn_model = create_cnn()\n",
    "combined_input = concatenate([ann_model.output, cnn_model.output])\n",
    "x = Dense(50, activation=\"relu\")(combined_input)\n",
    "x = Dense(6, activation=\"softmax\")(x)\n",
    "combined_model = Model(inputs=[ann_model.input, cnn_model.input], outputs=x)\n",
    "combined_model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "combined_model.fit(\n",
    "\tx=[x_train_attr, x_train_img], y=y_train,\n",
    "\tvalidation_data=([x_val_attr, x_val_img], y_val),\n",
    "\tepochs=20, batch_size=50)\n",
    "time_taken = time.time() - start_time\n",
    "print(\"Total time taken for the program execution\", time_taken) # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = combined_model.evaluate([x_train_attr, x_train_img], y_train, verbose=0)\n",
    "print(f'Train loss: {score[0]} / Train accuracy: {score[1]}')\n",
    "score = combined_model.evaluate([x_test_attr, x_test_img], y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = combined_model.predict([x_test_attr, x_test_img])\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(classification_report(y_test, pred, digits=5))"
   ]
  }
 ]
}