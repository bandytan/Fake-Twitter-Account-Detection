{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66f02fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:22.788933Z",
     "start_time": "2022-11-13T06:56:22.777028Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae51145",
   "metadata": {},
   "source": [
    "<h1>Import Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f3c7878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:22.795241Z",
     "start_time": "2022-11-13T06:56:22.792138Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \"data/\"\n",
    "has_face_pkl_path = \"data/has_face.pkl\"\n",
    "reciprocity_path = \"data/reciprocity.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd2278",
   "metadata": {},
   "source": [
    "# Get tweets corpus and join to dataset (may skip running if dataset is updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4dc4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(\"data\\combined_twitter_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3045bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:19: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:21: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:21: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_10732\\3352697936.py:21: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
     ]
    }
   ],
   "source": [
    "# get tweets df\n",
    "filenames_tweets = [\n",
    "    \"data/all tweets 2017/tweets_fake_followers.csv\",\n",
    "    \"data/all tweets 2017/tweets_genuine_accounts.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_1.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_2.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_3.csv\",\n",
    "    \"data/all tweets 2017/tweets_traditional_spambots_1.csv\",\n",
    "\n",
    "    \"data/tweets 2015/tweets_E13.csv\",\n",
    "    \"data/tweets 2015/tweets_FSF.csv\",\n",
    "    \"data/tweets 2015/tweets_INT.csv\",\n",
    "    \"data/tweets 2015/tweets_TFP.csv\",\n",
    "    \"data/tweets 2015/tweets_TWT.csv\"\n",
    "]\n",
    "\n",
    "for i,fn in enumerate(filenames_tweets):\n",
    "    if i == 0:\n",
    "        df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
    "    else:\n",
    "        df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdc0ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.dropna(subset = [\"user_id\"]) # drop those tweet with no userid\n",
    "df_tweets[\"user_id\"] = df_tweets[\"user_id\"].apply(int) # convert user_id to int\n",
    "df_tweets['timestamp'] = pd.to_datetime(df_tweets['timestamp']) # convert to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59e77e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort based on user_id (ascendign) then tweet time (descending: earliest is first)\n",
    "\n",
    "df_tweets = df_tweets.sort_values(\n",
    "    [\"user_id\", \"timestamp\"],\n",
    "    ascending=[True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9ffbde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n"
     ]
    }
   ],
   "source": [
    "# Create dict of tweets k,v = user_id, listoftweets\n",
    "# Takes 10-15 mins to run\n",
    "\n",
    "dict_tweets = {}\n",
    "\n",
    "for i in range(len(df_tweets)):\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    row = df_tweets.iloc[i,:]\n",
    "    user_id = row[\"user_id\"]\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    if user_id not in dict_tweets.keys():\n",
    "        dict_tweets[user_id] = [text]\n",
    "    else:\n",
    "        dict_tweets[user_id].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70474a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for list of tweets\n",
    "df_users['tweets_list'] = df_users['id'].map(dict_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5d811c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df with tweets corpus\n",
    "df_users.to_csv(\"data/combined_twitter_data_with_tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763348e",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ebfa370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:26.484782Z",
     "start_time": "2022-11-13T06:56:22.796886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read df with tweets corpus\n",
    "df_users = pd.read_csv(base + \"/combined_twitter_data_with_tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d60d3810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:26.491765Z",
     "start_time": "2022-11-13T06:56:26.485735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'name', 'screen_name',\n",
       "       'statuses_count', 'followers_count', 'friends_count',\n",
       "       'favourites_count', 'listed_count', 'url', 'lang', 'time_zone',\n",
       "       'location', 'default_profile', 'default_profile_image', 'geo_enabled',\n",
       "       'profile_image_url', 'profile_banner_url',\n",
       "       'profile_use_background_image', 'profile_background_image_url_https',\n",
       "       'profile_text_color', 'profile_image_url_https',\n",
       "       'profile_sidebar_border_color', 'profile_background_tile',\n",
       "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
       "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
       "       'protected', 'verified', 'description', 'created_at', 'updated',\n",
       "       'account_type', 'tweets_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3c55f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324af6f",
   "metadata": {},
   "source": [
    "### Remove columns that are redundant\n",
    "Data is redundant in helping us with our problem statement when:\n",
    "- The data is metadata\n",
    "- There are too many unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7fa513ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.099625Z",
     "start_time": "2022-11-13T06:57:12.096584Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_list = ['Unnamed: 0.1', 'Unnamed: 0', 'lang', 'time_zone', 'location', 'profile_banner_url', 'profile_background_image_url_https',\n",
    "       'profile_text_color', 'profile_image_url_https', 'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
    "       'profile_background_image_url', 'profile_background_color', 'profile_link_color', 'utc_offset', 'created_at', 'updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0009e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.127707Z",
     "start_time": "2022-11-13T06:57:12.100893Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop(remove_list, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd05b0",
   "metadata": {},
   "source": [
    "### Replace NaN values with zeros for binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "624f87a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.134439Z",
     "start_time": "2022-11-13T06:57:12.129044Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users['default_profile'] = df_users['default_profile'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['geo_enabled'] = df_users['geo_enabled'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['profile_use_background_image'] = df_users['profile_use_background_image'].fillna(0)\n",
    "df_users['profile_background_tile'] = df_users['profile_background_tile'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6a871",
   "metadata": {},
   "source": [
    "<h2>Train Test Split (85-15)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "540a7261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.205471Z",
     "start_time": "2022-11-13T06:57:12.135837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake    8362\n",
      "real    2751\n",
      "Name: account_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#get the target variable - real or fake account type - binary classification problem\n",
    "df_users = df_users[(df_users['account_type'] == \"real\") | (df_users['account_type'] == \"fake\")]\n",
    "print(df_users['account_type'].value_counts())\n",
    "df_users['account_type'] = df_users['account_type'].apply(lambda x: 0 if x==\"fake\" else 1)\n",
    "\n",
    "train, test = train_test_split(df_users, test_size=0.15, random_state=69, stratify=df_users['account_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77d646c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.209526Z",
     "start_time": "2022-11-13T06:57:12.207110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 9446\n",
      "test size 1667\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", len(train))\n",
    "print(\"test size\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b7303ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.214700Z",
     "start_time": "2022-11-13T06:57:12.211370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7108\n",
       "1    2338\n",
       "Name: account_type, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['account_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa59a12",
   "metadata": {},
   "source": [
    "<h2>Date Formatting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b98154f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:13.380341Z",
     "start_time": "2022-11-13T06:57:12.215773Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes around 10 min to run\n",
    "df_tweets['created_at_formatted'] = pd.to_datetime(df_tweets['timestamp'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38598aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.539209Z",
     "start_time": "2022-11-13T06:57:13.383166Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets['created_at_date'] = df_tweets['created_at_formatted'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4398af",
   "metadata": {},
   "source": [
    "<h2>Tweet features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03f36ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.543885Z",
     "start_time": "2022-11-13T06:57:19.540132Z"
    }
   },
   "outputs": [],
   "source": [
    "def tweet_freq(df_users, df_tweets):\n",
    "    \n",
    "    # user tweet frequency = total number of tweets / number of user active days \n",
    "    # shows how often the user tweets among the days that a user tweets at least once. User activity is defined by whether the user tweets in a given day\n",
    "    # 1 = user tweets only once per active day \n",
    "    # >1 = user tweets more than once a day on average, in the days that the user is active \n",
    "\n",
    "    df_tweets_per_day = df_tweets.groupby(by=[\"user_id\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                              date_count=('created_at_date', lambda x: x.nunique()))\n",
    "\n",
    "    dict_tweets_average = {user_id: df_tweets_per_day.loc[user_id]['tweet_count'] / df_tweets_per_day.loc[user_id]['date_count'] for user_id in df_tweets_per_day.index}\n",
    "    #create new column for user tweet frequency \n",
    "    df_users['tweet_frequency'] = df_users['id'].map(dict_tweets_average)\n",
    "    df_users['tweet_frequency'] = df_users['tweet_frequency'].fillna(0)\n",
    "    return df_users\n",
    "\n",
    "def tweet_tags_mention(df_users, df_tweets):\n",
    "    # average number of tags per post = total number of tags used per tweet \n",
    "    # average number of mentions per post = total number of mentions per tweet \n",
    "\n",
    "    df_tweets['text'] = df_tweets['text'].apply(str) #convert all text to string\n",
    "    df_tweets['number_of_tags'] = df_tweets['text'].apply(lambda x: x.count(\"#\"))\n",
    "    df_tweets['number_of_mentions'] = df_tweets['text'].apply(lambda x: x.count(\"@\"))\n",
    "    tags_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_tags'].sum().to_dict()\n",
    "    mentions_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_mentions'].sum().to_dict() \n",
    "\n",
    "    #create new column for number of tags\n",
    "    df_users['number_of_tags'] = df_users['id'].map(tags_dict)\n",
    "    #create new column for number of mentions\n",
    "    df_users['number_of_mentions'] = df_users['id'].map(mentions_dict)\n",
    "    \n",
    "    df_users['number_of_mentions'] = df_users['number_of_mentions'].fillna(0)\n",
    "    df_users['number_of_tags'] = df_users['number_of_tags'].fillna(0)\n",
    "    return df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d082f56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.548167Z",
     "start_time": "2022-11-13T06:57:19.544776Z"
    }
   },
   "outputs": [],
   "source": [
    "# return 0 if weekend, 1 if weekday \n",
    "def is_weekday(dt):\n",
    "    return 0 if dt.weekday() > 4 else 1\n",
    "\n",
    "# return day of week \n",
    "def get_weekday(dt):\n",
    "    return dt.weekday()\n",
    "\n",
    "def get_weekend_weekday_frequency(df_tweets, df_users):\n",
    "    df_tweets['weekday'] = df_tweets['created_at_formatted'].apply(lambda x: is_weekday(x))\n",
    "    df_tweets_weekday_weekend = df_tweets.groupby(by=[\"user_id\", \"weekday\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                          date_count=('created_at_date', lambda x: x.nunique()))\n",
    "    dict_tweets_weekend = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 0}\n",
    "    df_users['tweet_weekend_frequency'] = df_users['id'].map(dict_tweets_weekend)        \n",
    "    dict_tweets_weekday = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 1}\n",
    "    df_users['tweet_weekday_frequency'] = df_users['id'].map(dict_tweets_weekday)\n",
    "    \n",
    "    df_users['tweet_weekend_frequency'] = df_users['tweet_weekend_frequency'].fillna(0)\n",
    "    df_users['tweet_weekday_frequency'] = df_users['tweet_weekday_frequency'].fillna(0)\n",
    "    return df_users      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d1618",
   "metadata": {},
   "source": [
    "<h2>Followers To Following Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "828f63cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.551329Z",
     "start_time": "2022-11-13T06:57:19.548932Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_followers_following_ratio(df):\n",
    "    #followers divide by following (high means popular, low means more following)\n",
    "    df['following_to_followers_ratio'] = df['friends_count'] / df['followers_count']\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].fillna(0)\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].apply(lambda x: 1 if x == np.inf else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857742c6",
   "metadata": {},
   "source": [
    "<h2>Name Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8cc2904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.555071Z",
     "start_time": "2022-11-13T06:57:19.552182Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_features(df):\n",
    "    #get length of username and screen name\n",
    "    df['username_length'] = df['name'].apply(lambda x: len(str(x)))\n",
    "    df['screen_name_length'] = df['screen_name'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    #anything that is not a-z or 0-9 will be blocked, outputs length\n",
    "    df['username_spec_char_count'] = df['name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    df['screen_name_spec_char_count'] = df['screen_name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ded964",
   "metadata": {},
   "source": [
    "<h2>Has URL Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f26a4f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.558576Z",
     "start_time": "2022-11-13T06:57:19.556222Z"
    }
   },
   "outputs": [],
   "source": [
    "def has_url_feature(df):\n",
    "    #1 if has url, 0 if no url\n",
    "    df['has_url'] = df['url'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ded964",
   "metadata": {},
   "source": [
    "<h2>Has Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f26a4f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.558576Z",
     "start_time": "2022-11-13T06:57:19.556222Z"
    }
   },
   "outputs": [],
   "source": [
    "def has_description(df):\n",
    "    #1 if has description, 0 if no description\n",
    "    df['has_desc'] = df['description'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463fa9a",
   "metadata": {},
   "source": [
    "<h2>Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eff62399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.563004Z",
     "start_time": "2022-11-13T06:57:19.559583Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_texts(df):\n",
    "    def process_tweets_list(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for tweet_list in corpus:\n",
    "            tweet_list = str(tweet_list)\n",
    "            row_processed = \"\"\n",
    "            \n",
    "            #replace RT and @\n",
    "            row_processed = tweet_list.replace(\"RT\", \"\" ) \n",
    "            row_processed = row_processed.replace(\"@\", \"\" )\n",
    "            \n",
    "            row_processed = re.sub(r'http\\S+', \"\", row_processed) #remove any URLs in tweets\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row_processed) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "\n",
    "        return corpus_processed\n",
    "    \n",
    "    def process_description(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for row in corpus:\n",
    "            row = str(row)\n",
    "            # row_processed = re.sub(\"account\", \"\", row) # remove word \"account\"\n",
    "            # row_processed = re.sub(\"geo-targeted\", \"\", row_processed) # remove phrase \"geo-targeted\"\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "        return corpus_processed\n",
    "    \n",
    "    df[\"tweets_list_processed\"] = process_tweets_list(df[\"tweets_list\"])\n",
    "    df[\"description_processed\"] = process_description(df[\"description\"])\n",
    "    \n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cac20b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.566517Z",
     "start_time": "2022-11-13T06:57:19.564172Z"
    }
   },
   "outputs": [],
   "source": [
    "class LemmatizeTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, text):\n",
    "        return [self.lemmatizer.lemmatize(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfaf4de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.592461Z",
     "start_time": "2022-11-13T06:57:19.587339Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_nlp_features(df):\n",
    "\n",
    "    tfidf_feature_names = {}\n",
    "\n",
    "    max_tfidf_features = 100\n",
    "    \n",
    "    #tweets\n",
    "    vect_tweets = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=max_tfidf_features, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    tweets_processed = pd.Series(df[\"tweets_list_processed\"])\n",
    "    tfidf_fit_tweets = vect_tweets.fit(tweets_processed)\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(tweets_processed).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x: \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    tfidf_feature_names[\"tweets\"] = list(zip(range(max_tfidf_features),vect_tweets.get_feature_names()))\n",
    "    \n",
    "    #description\n",
    "    vect_description = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=max_tfidf_features, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    description_processed = pd.Series(df[\"description_processed\"])\n",
    "    tfidf_fit_description = vect_description.fit(description_processed)\n",
    "    description_tfidf_array = tfidf_fit_description.transform(description_processed).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x: \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    tfidf_feature_names[\"description\"] = list(zip(range(max_tfidf_features),vect_description.get_feature_names()))\n",
    "\n",
    "\n",
    "    \n",
    "    return (df, tfidf_fit_tweets, tfidf_fit_description, tfidf_feature_names)\n",
    "\n",
    "def nlp_transform_test(df, tfidf_fit_tweets, tfidf_fit_description):\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(df['tweets_list_processed']).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x : \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    description_tfidf_array = tfidf_fit_description.transform(df['description_processed']).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x : \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282b893",
   "metadata": {},
   "source": [
    "## Has Face Feature (Face Detection with MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68e485e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.599299Z",
     "start_time": "2022-11-13T06:57:19.593608Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the mapping and attach to df during combine\n",
    "with open(has_face_pkl_path, 'rb') as f:\n",
    "    has_face_d = pickle.load(f)\n",
    "\n",
    "has_face_d = {int(k):v for k,v in has_face_d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13d25e",
   "metadata": {},
   "source": [
    "## Graph Analysis: Reciprocity of each user \n",
    "- The ratio of the number of relations which are reciprocated over the total number of relations in a directed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fbf40d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.603244Z",
     "start_time": "2022-11-13T06:57:19.600188Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the mapping and attach to df during combine\n",
    "with open(reciprocity_path, 'rb') as f:\n",
    "    reci_d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4ac4b",
   "metadata": {},
   "source": [
    "<h2>Combine all Feature Generating Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ff95beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:13:18.234385Z",
     "start_time": "2022-11-13T06:57:19.604172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "result = tweet_freq(train, df_tweets)\n",
    "result = tweet_tags_mention(result, df_tweets)\n",
    "result = get_weekend_weekday_frequency(df_tweets, result)\n",
    "result = create_followers_following_ratio(result)\n",
    "result = name_features(result)\n",
    "result = has_url_feature(result)\n",
    "result = has_description(result)\n",
    "result = clean_texts(result)\n",
    "result, tfidf_fit_tweets, tfidf_fit_description, tfidf_feature_names = generate_nlp_features(result)\n",
    "result['has_face'] = result['id'].map(has_face_d)\n",
    "result['reciprocity'] = result['id'].map(reci_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "615aeb44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:13:18.298031Z",
     "start_time": "2022-11-13T07:13:18.236126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82118682</td>\n",
       "      <td>davide gazzÃ¨</td>\n",
       "      <td>davidegazze</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1174756808</td>\n",
       "      <td>Carolee Moberly</td>\n",
       "      <td>MoberlycikCarol</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>708732794</td>\n",
       "      <td>Julius Kirk</td>\n",
       "      <td>juliuskirkdoq</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360642101</td>\n",
       "      <td>Magan Skripko</td>\n",
       "      <td>MaganSkripko</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2379608905</td>\n",
       "      <td>Martin Bruley</td>\n",
       "      <td>MartinBruley</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>2363037596</td>\n",
       "      <td>Ula Banegas</td>\n",
       "      <td>UlaBanegas</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9442</th>\n",
       "      <td>1175035327</td>\n",
       "      <td>Jasmine Finkelstein</td>\n",
       "      <td>FinkelsteinupdJ</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>67631743</td>\n",
       "      <td>TMJ-Morocco Jobs</td>\n",
       "      <td>tmj_mar_jobs1</td>\n",
       "      <td>49</td>\n",
       "      <td>582</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>2370803990</td>\n",
       "      <td>Christy Schnicke</td>\n",
       "      <td>ChristySchnicke</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>2360933791</td>\n",
       "      <td>Abbey Pelaez</td>\n",
       "      <td>AbbeyPelaez</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9446 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 name      screen_name  statuses_count  \\\n",
       "0       82118682        davide gazzÃ¨      davidegazze              88   \n",
       "1     1174756808      Carolee Moberly  MoberlycikCarol              19   \n",
       "2      708732794          Julius Kirk    juliuskirkdoq              22   \n",
       "3     2360642101        Magan Skripko     MaganSkripko              47   \n",
       "4     2379608905        Martin Bruley     MartinBruley              34   \n",
       "...          ...                  ...              ...             ...   \n",
       "9441  2363037596          Ula Banegas       UlaBanegas              53   \n",
       "9442  1175035327  Jasmine Finkelstein  FinkelsteinupdJ              22   \n",
       "9443    67631743     TMJ-Morocco Jobs    tmj_mar_jobs1              49   \n",
       "9444  2370803990     Christy Schnicke  ChristySchnicke              64   \n",
       "9445  2360933791         Abbey Pelaez      AbbeyPelaez              35   \n",
       "\n",
       "      followers_count  friends_count  favourites_count  listed_count  \\\n",
       "0                  19             39                 9             0   \n",
       "1                   7            192                 0             0   \n",
       "2                  11            241                 0             0   \n",
       "3                   6             41                 0             0   \n",
       "4                   4             36                 0             0   \n",
       "...               ...            ...               ...           ...   \n",
       "9441                6             36                 0             0   \n",
       "9442                8            194                 0             0   \n",
       "9443              582            494                 0            53   \n",
       "9444               11             43                 0             0   \n",
       "9445                7             42                 0             0   \n",
       "\n",
       "                          url  default_profile  ...  description_92  \\\n",
       "0                         NaN              0.0  ...             0.0   \n",
       "1                         NaN              1.0  ...             0.0   \n",
       "2                         NaN              1.0  ...             0.0   \n",
       "3                         NaN              0.0  ...             0.0   \n",
       "4                         NaN              0.0  ...             0.0   \n",
       "...                       ...              ...  ...             ...   \n",
       "9441                      NaN              0.0  ...             0.0   \n",
       "9442                      NaN              1.0  ...             0.0   \n",
       "9443  https://t.co/DByWt45HZj              0.0  ...             0.0   \n",
       "9444                      NaN              0.0  ...             0.0   \n",
       "9445                      NaN              0.0  ...             0.0   \n",
       "\n",
       "      description_93 description_94  description_95  description_96  \\\n",
       "0                0.0            0.0             0.0             0.0   \n",
       "1                0.0            0.0             0.0             0.0   \n",
       "2                0.0            0.0             0.0             0.0   \n",
       "3                0.0            0.0             0.0             0.0   \n",
       "4                0.0            0.0             0.0             0.0   \n",
       "...              ...            ...             ...             ...   \n",
       "9441             0.0            0.0             0.0             0.0   \n",
       "9442             0.0            0.0             0.0             0.0   \n",
       "9443             0.0            0.0             0.0             0.0   \n",
       "9444             0.0            0.0             0.0             0.0   \n",
       "9445             0.0            0.0             0.0             0.0   \n",
       "\n",
       "      description_97  description_98 description_99  has_face reciprocity  \n",
       "0                0.0             0.0            0.0         1        0.75  \n",
       "1                0.0             0.0            0.0         1        0.00  \n",
       "2                0.0             0.0            0.0         1        0.00  \n",
       "3                0.0             0.0            0.0         1        0.00  \n",
       "4                0.0             0.0            0.0         1        0.00  \n",
       "...              ...             ...            ...       ...         ...  \n",
       "9441             0.0             0.0            0.0         1        0.00  \n",
       "9442             0.0             0.0            0.0         1        0.00  \n",
       "9443             0.0             0.0            0.0         0        0.00  \n",
       "9444             0.0             0.0            0.0         1        0.00  \n",
       "9445             0.0             0.0            0.0         0        0.00  \n",
       "\n",
       "[9446 rows x 236 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6ad70",
   "metadata": {},
   "source": [
    "## Apply same feature engineering on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bae570c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:25.516972Z",
     "start_time": "2022-11-13T07:13:18.304064Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tweet_freq(test, df_tweets)\n",
    "test = tweet_tags_mention(test, df_tweets)\n",
    "test = get_weekend_weekday_frequency(df_tweets, test)\n",
    "test = create_followers_following_ratio(test)\n",
    "test = name_features(test)\n",
    "test = has_url_feature(test)\n",
    "test = has_description(test)\n",
    "test = clean_texts(test)\n",
    "test = nlp_transform_test(test, tfidf_fit_tweets, tfidf_fit_description)\n",
    "test['has_face'] = test['id'].map(has_face_d)\n",
    "test['reciprocity'] = test['id'].map(reci_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39cb1d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:25.521120Z",
     "start_time": "2022-11-13T07:14:25.518212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "236\n"
     ]
    }
   ],
   "source": [
    "print(len(test.columns))\n",
    "print(len(result.columns))\n",
    "\n",
    "for i in result.columns:\n",
    "    if i not in test.columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e4e13",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a095632b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.855311Z",
     "start_time": "2022-11-13T07:14:25.536083Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"data/twitter_data_train.csv\", index=False)\n",
    "test.to_csv(\"data/twitter_data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48bd5870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.867642Z",
     "start_time": "2022-11-13T07:14:33.856236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, has_desc, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 236 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08957afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.875814Z",
     "start_time": "2022-11-13T07:14:33.868913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, has_desc, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 236 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2986687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tfidf_feature_names\n",
    "\n",
    "with open('data/tfidf_feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_feature_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "196a2188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweets': [(0, 'al'),\n",
       "  (1, 'always'),\n",
       "  (2, 'amp'),\n",
       "  (3, 'anche'),\n",
       "  (4, 'back'),\n",
       "  (5, 'best'),\n",
       "  (6, 'cant'),\n",
       "  (7, 'che'),\n",
       "  (8, 'check'),\n",
       "  (9, 'chi'),\n",
       "  (10, 'ci'),\n",
       "  (11, 'come'),\n",
       "  (12, 'con'),\n",
       "  (13, 'cool'),\n",
       "  (14, 'da'),\n",
       "  (15, 'day'),\n",
       "  (16, 'de'),\n",
       "  (17, 'dei'),\n",
       "  (18, 'del'),\n",
       "  (19, 'della'),\n",
       "  (20, 'di'),\n",
       "  (21, 'dont'),\n",
       "  (22, 'e'),\n",
       "  (23, 'essere'),\n",
       "  (24, 'get'),\n",
       "  (25, 'gli'),\n",
       "  (26, 'go'),\n",
       "  (27, 'going'),\n",
       "  (28, 'good'),\n",
       "  (29, 'got'),\n",
       "  (30, 'great'),\n",
       "  (31, 'great introduction'),\n",
       "  (32, 'ha'),\n",
       "  (33, 'history'),\n",
       "  (34, 'ho'),\n",
       "  (35, 'il'),\n",
       "  (36, 'im'),\n",
       "  (37, 'introduction'),\n",
       "  (38, 'io'),\n",
       "  (39, 'know'),\n",
       "  (40, 'la'),\n",
       "  (41, 'le'),\n",
       "  (42, 'learn'),\n",
       "  (43, 'life'),\n",
       "  (44, 'like'),\n",
       "  (45, 'lo'),\n",
       "  (46, 'lol'),\n",
       "  (47, 'look'),\n",
       "  (48, 'love'),\n",
       "  (49, 'mai'),\n",
       "  (50, 'make'),\n",
       "  (51, 'man'),\n",
       "  (52, 'mi'),\n",
       "  (53, 'money'),\n",
       "  (54, 'much'),\n",
       "  (55, 'na'),\n",
       "  (56, 'need'),\n",
       "  (57, 'never'),\n",
       "  (58, 'new'),\n",
       "  (59, 'non'),\n",
       "  (60, 'one'),\n",
       "  (61, 'people'),\n",
       "  (62, 'per'),\n",
       "  (63, 'perch'),\n",
       "  (64, 'pi'),\n",
       "  (65, 'quando'),\n",
       "  (66, 'read'),\n",
       "  (67, 'read history'),\n",
       "  (68, 'really'),\n",
       "  (69, 'right'),\n",
       "  (70, 'say'),\n",
       "  (71, 'se'),\n",
       "  (72, 'see'),\n",
       "  (73, 'sempre'),\n",
       "  (74, 'shoe'),\n",
       "  (75, 'si'),\n",
       "  (76, 'solo'),\n",
       "  (77, 'something'),\n",
       "  (78, 'sono'),\n",
       "  (79, 'su'),\n",
       "  (80, 'take'),\n",
       "  (81, 'te'),\n",
       "  (82, 'thing'),\n",
       "  (83, 'think'),\n",
       "  (84, 'ti'),\n",
       "  (85, 'time'),\n",
       "  (86, 'today'),\n",
       "  (87, 'tutti'),\n",
       "  (88, 'twitter'),\n",
       "  (89, 'u'),\n",
       "  (90, 'un'),\n",
       "  (91, 'una'),\n",
       "  (92, 'via'),\n",
       "  (93, 'wa'),\n",
       "  (94, 'want'),\n",
       "  (95, 'way'),\n",
       "  (96, 'work'),\n",
       "  (97, 'world'),\n",
       "  (98, 'would'),\n",
       "  (99, 'youre')],\n",
       " 'description': [(0, '2'),\n",
       "  (1, 'account'),\n",
       "  (2, 'account geotargeted'),\n",
       "  (3, 'account geotargeted businessmgmt'),\n",
       "  (4, 'account geotargeted customer'),\n",
       "  (5, 'account geotargeted job'),\n",
       "  (6, 'back'),\n",
       "  (7, 'blog'),\n",
       "  (8, 'business'),\n",
       "  (9, 'businessmgmt'),\n",
       "  (10, 'businessmgmt job'),\n",
       "  (11, 'businessmgmt job tweet'),\n",
       "  (12, 'careerarc'),\n",
       "  (13, 'che'),\n",
       "  (14, 'click'),\n",
       "  (15, 'click link'),\n",
       "  (16, 'code'),\n",
       "  (17, 'customer'),\n",
       "  (18, 'customer service'),\n",
       "  (19, 'customer service job'),\n",
       "  (20, 'da'),\n",
       "  (21, 'de'),\n",
       "  (22, 'di'),\n",
       "  (23, 'dont'),\n",
       "  (24, 'e'),\n",
       "  (25, 'enter'),\n",
       "  (26, 'fan'),\n",
       "  (27, 'follow'),\n",
       "  (28, 'follow account'),\n",
       "  (29, 'follow account geotargeted'),\n",
       "  (30, 'friend'),\n",
       "  (31, 'geotargeted'),\n",
       "  (32, 'geotargeted businessmgmt'),\n",
       "  (33, 'geotargeted businessmgmt job'),\n",
       "  (34, 'geotargeted customer'),\n",
       "  (35, 'geotargeted customer service'),\n",
       "  (36, 'geotargeted job'),\n",
       "  (37, 'geotargeted job tweet'),\n",
       "  (38, 'get'),\n",
       "  (39, 'help'),\n",
       "  (40, 'help tweet'),\n",
       "  (41, 'help tweet u'),\n",
       "  (42, 'hiring'),\n",
       "  (43, 'il'),\n",
       "  (44, 'im'),\n",
       "  (45, 'java'),\n",
       "  (46, 'job'),\n",
       "  (47, 'job tweet'),\n",
       "  (48, 'know'),\n",
       "  (49, 'la'),\n",
       "  (50, 'le'),\n",
       "  (51, 'life'),\n",
       "  (52, 'like'),\n",
       "  (53, 'link'),\n",
       "  (54, 'love'),\n",
       "  (55, 'lover'),\n",
       "  (56, 'make'),\n",
       "  (57, 'medium'),\n",
       "  (58, 'member'),\n",
       "  (59, 'member twitter'),\n",
       "  (60, 'mi'),\n",
       "  (61, 'music'),\n",
       "  (62, 'need'),\n",
       "  (63, 'need help'),\n",
       "  (64, 'need help tweet'),\n",
       "  (65, 'new'),\n",
       "  (66, 'non'),\n",
       "  (67, 'nonmetro'),\n",
       "  (68, 'nonmetro need'),\n",
       "  (69, 'nonmetro need help'),\n",
       "  (70, 'one'),\n",
       "  (71, 'open'),\n",
       "  (72, 'people'),\n",
       "  (73, 'per'),\n",
       "  (74, 'prize'),\n",
       "  (75, 'que'),\n",
       "  (76, 'resource'),\n",
       "  (77, 'se'),\n",
       "  (78, 'service'),\n",
       "  (79, 'service job'),\n",
       "  (80, 'service job tweet'),\n",
       "  (81, 'site'),\n",
       "  (82, 'social'),\n",
       "  (83, 'social medium'),\n",
       "  (84, 'software'),\n",
       "  (85, 'time'),\n",
       "  (86, 'tweet'),\n",
       "  (87, 'tweet u'),\n",
       "  (88, 'tweet u careerarc'),\n",
       "  (89, 'twitter'),\n",
       "  (90, 'u'),\n",
       "  (91, 'u careerarc'),\n",
       "  (92, 'un'),\n",
       "  (93, 'una'),\n",
       "  (94, 'unique'),\n",
       "  (95, 'web'),\n",
       "  (96, 'winner'),\n",
       "  (97, 'winner unique'),\n",
       "  (98, 'world'),\n",
       "  (99, 'writer')]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39faaace",
   "metadata": {},
   "source": [
    "## Get multiclass label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d95df67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.685231Z",
     "start_time": "2022-11-13T07:20:13.726833Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/twitter_data_train.csv\")\n",
    "test_df = pd.read_csv(\"data/twitter_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bf1e0556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.696820Z",
     "start_time": "2022-11-13T07:20:18.686166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, has_desc, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 236 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b1742df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.712381Z",
     "start_time": "2022-11-13T07:20:18.697703Z"
    }
   },
   "outputs": [],
   "source": [
    "df_import = pd.read_csv(\"data/cresci2017/traditional_spambots_4.csv\")\n",
    "#df_import = pd.read_csv(\"/Users/ivankoh/Downloads/traditional_spambots_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "539e65d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.771976Z",
     "start_time": "2022-11-13T07:20:18.752956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>notifications</th>\n",
       "      <th>description</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>following</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21478911</td>\n",
       "      <td>TMJ- CLT Util Jobs</td>\n",
       "      <td>tmj_clt_util</td>\n",
       "      <td>4</td>\n",
       "      <td>344</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Utilities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Feb 21 12:04:47 +0000 2009</td>\n",
       "      <td>2009-02-21 13:04:47</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21479094</td>\n",
       "      <td>TMJ - SFO Util Jobs</td>\n",
       "      <td>tmj_sfo_util</td>\n",
       "      <td>3</td>\n",
       "      <td>353</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Utilities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Feb 21 12:09:26 +0000 2009</td>\n",
       "      <td>2009-02-21 13:09:26</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21479204</td>\n",
       "      <td>TMJ - WAS Util Jobs</td>\n",
       "      <td>tmj_dc_util</td>\n",
       "      <td>1</td>\n",
       "      <td>323</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Utilities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Feb 21 12:12:01 +0000 2009</td>\n",
       "      <td>2009-02-21 13:12:01</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21479275</td>\n",
       "      <td>TMJ - JAX Util Jobs</td>\n",
       "      <td>tmj_jax_util</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Utilities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Feb 21 12:13:37 +0000 2009</td>\n",
       "      <td>2009-02-21 13:13:37</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21479334</td>\n",
       "      <td>TMJ - CHI Util Jobs</td>\n",
       "      <td>tmj_chi_util</td>\n",
       "      <td>6</td>\n",
       "      <td>339</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Utilities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Feb 21 12:15:21 +0000 2009</td>\n",
       "      <td>2009-02-21 13:15:21</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "      <td>2016-03-15 13:48:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>818079408</td>\n",
       "      <td>Columbia Facil. Mgmt</td>\n",
       "      <td>tmj_cae_facmgmt</td>\n",
       "      <td>41</td>\n",
       "      <td>169</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>http://t.co/TKb82K4tFJ</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Facilitie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Sep 11 20:00:43 +0000 2012</td>\n",
       "      <td>2012-09-11 22:00:43</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>846108068</td>\n",
       "      <td>NJ Business/Mgmt</td>\n",
       "      <td>tmj_nj_mgmt</td>\n",
       "      <td>218</td>\n",
       "      <td>332</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>https://t.co/DByWt4njnT</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Business/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Sep 25 19:35:53 +0000 2012</td>\n",
       "      <td>2012-09-25 21:35:53</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>857076271</td>\n",
       "      <td>PR Customer Ser.</td>\n",
       "      <td>tmj_ptr_cstsrv</td>\n",
       "      <td>17</td>\n",
       "      <td>530</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>http://t.co/paWgrkSWfT</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Customer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon Oct 01 21:47:23 +0000 2012</td>\n",
       "      <td>2012-10-01 23:47:23</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>872126906</td>\n",
       "      <td>PR Soft Dev Java</td>\n",
       "      <td>tmj_ptr_itjava</td>\n",
       "      <td>2</td>\n",
       "      <td>247</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/OnFSpFHC7G</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Software ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Oct 10 16:44:09 +0000 2012</td>\n",
       "      <td>2012-10-10 18:44:09</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>979406250</td>\n",
       "      <td>Harrisburg Cust. Ser</td>\n",
       "      <td>tmj_hpa_cstsrv</td>\n",
       "      <td>47</td>\n",
       "      <td>267</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>http://t.co/Kz252i4r</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow this account for geo-targeted Customer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri Nov 30 00:08:26 +0000 2012</td>\n",
       "      <td>2012-11-30 01:08:26</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "      <td>2016-03-15 13:49:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                  name      screen_name  statuses_count  \\\n",
       "0      21478911    TMJ- CLT Util Jobs     tmj_clt_util               4   \n",
       "1      21479094   TMJ - SFO Util Jobs     tmj_sfo_util               3   \n",
       "2      21479204   TMJ - WAS Util Jobs      tmj_dc_util               1   \n",
       "3      21479275   TMJ - JAX Util Jobs     tmj_jax_util               4   \n",
       "4      21479334   TMJ - CHI Util Jobs     tmj_chi_util               6   \n",
       "...         ...                   ...              ...             ...   \n",
       "1123  818079408  Columbia Facil. Mgmt  tmj_cae_facmgmt              41   \n",
       "1124  846108068      NJ Business/Mgmt      tmj_nj_mgmt             218   \n",
       "1125  857076271      PR Customer Ser.   tmj_ptr_cstsrv              17   \n",
       "1126  872126906      PR Soft Dev Java   tmj_ptr_itjava               2   \n",
       "1127  979406250  Harrisburg Cust. Ser   tmj_hpa_cstsrv              47   \n",
       "\n",
       "      followers_count  friends_count  favourites_count  listed_count  \\\n",
       "0                 344            295                 0             5   \n",
       "1                 353            322                 0            16   \n",
       "2                 323            294                 0             2   \n",
       "3                 311            292                 0             4   \n",
       "4                 339            298                 0             7   \n",
       "...               ...            ...               ...           ...   \n",
       "1123              169            151                 0            12   \n",
       "1124              332            245                 0            31   \n",
       "1125              530            300                 0             8   \n",
       "1126              247            202                 0             1   \n",
       "1127              267            234                 0             7   \n",
       "\n",
       "                          url lang  ... protected verified  notifications  \\\n",
       "0     https://t.co/DByWt45HZj   en  ...       NaN      NaN            NaN   \n",
       "1     https://t.co/DByWt45HZj   en  ...       NaN      NaN            NaN   \n",
       "2     https://t.co/DByWt45HZj   en  ...       NaN      NaN            NaN   \n",
       "3     https://t.co/DByWt45HZj   en  ...       NaN      NaN            NaN   \n",
       "4     https://t.co/DByWt45HZj   en  ...       NaN      NaN            NaN   \n",
       "...                       ...  ...  ...       ...      ...            ...   \n",
       "1123   http://t.co/TKb82K4tFJ   en  ...       NaN      NaN            NaN   \n",
       "1124  https://t.co/DByWt4njnT   en  ...       NaN      NaN            NaN   \n",
       "1125   http://t.co/paWgrkSWfT   en  ...       NaN      NaN            NaN   \n",
       "1126   http://t.co/OnFSpFHC7G   en  ...       NaN      NaN            NaN   \n",
       "1127     http://t.co/Kz252i4r   en  ...       NaN      NaN            NaN   \n",
       "\n",
       "                                            description  contributors_enabled  \\\n",
       "0     Follow this account for geo-targeted Utilities...                   NaN   \n",
       "1     Follow this account for geo-targeted Utilities...                   NaN   \n",
       "2     Follow this account for geo-targeted Utilities...                   NaN   \n",
       "3     Follow this account for geo-targeted Utilities...                   NaN   \n",
       "4     Follow this account for geo-targeted Utilities...                   NaN   \n",
       "...                                                 ...                   ...   \n",
       "1123  Follow this account for geo-targeted Facilitie...                   NaN   \n",
       "1124  Follow this account for geo-targeted Business/...                   NaN   \n",
       "1125  Follow this account for geo-targeted Customer ...                   NaN   \n",
       "1126  Follow this account for geo-targeted Software ...                   NaN   \n",
       "1127  Follow this account for geo-targeted Customer ...                   NaN   \n",
       "\n",
       "     following                      created_at            timestamp  \\\n",
       "0          NaN  Sat Feb 21 12:04:47 +0000 2009  2009-02-21 13:04:47   \n",
       "1          NaN  Sat Feb 21 12:09:26 +0000 2009  2009-02-21 13:09:26   \n",
       "2          NaN  Sat Feb 21 12:12:01 +0000 2009  2009-02-21 13:12:01   \n",
       "3          NaN  Sat Feb 21 12:13:37 +0000 2009  2009-02-21 13:13:37   \n",
       "4          NaN  Sat Feb 21 12:15:21 +0000 2009  2009-02-21 13:15:21   \n",
       "...        ...                             ...                  ...   \n",
       "1123       NaN  Tue Sep 11 20:00:43 +0000 2012  2012-09-11 22:00:43   \n",
       "1124       NaN  Tue Sep 25 19:35:53 +0000 2012  2012-09-25 21:35:53   \n",
       "1125       NaN  Mon Oct 01 21:47:23 +0000 2012  2012-10-01 23:47:23   \n",
       "1126       NaN  Wed Oct 10 16:44:09 +0000 2012  2012-10-10 18:44:09   \n",
       "1127       NaN  Fri Nov 30 00:08:26 +0000 2012  2012-11-30 01:08:26   \n",
       "\n",
       "               crawled_at              updated  \n",
       "0     2016-03-15 13:48:59  2016-03-15 13:48:59  \n",
       "1     2016-03-15 13:48:59  2016-03-15 13:48:59  \n",
       "2     2016-03-15 13:48:59  2016-03-15 13:48:59  \n",
       "3     2016-03-15 13:48:59  2016-03-15 13:48:59  \n",
       "4     2016-03-15 13:48:59  2016-03-15 13:48:59  \n",
       "...                   ...                  ...  \n",
       "1123  2016-03-15 13:49:15  2016-03-15 13:49:15  \n",
       "1124  2016-03-15 13:49:15  2016-03-15 13:49:15  \n",
       "1125  2016-03-15 13:49:15  2016-03-15 13:49:15  \n",
       "1126  2016-03-15 13:49:15  2016-03-15 13:49:15  \n",
       "1127  2016-03-15 13:49:15  2016-03-15 13:49:15  \n",
       "\n",
       "[1128 rows x 40 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce4fe1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.918055Z",
     "start_time": "2022-11-13T07:20:18.773165Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ff = pd.read_csv(\"data/cresci2017/fake_followers.csv\")\n",
    "ga = pd.read_csv(\"data/cresci2017/genuine_accounts.csv\") # real\n",
    "ss1 = pd.read_csv(\"data/cresci2017/social_spambots_1.csv\")\n",
    "ss2 = pd.read_csv(\"data/cresci2017/social_spambots_2.csv\")\n",
    "ss3 = pd.read_csv(\"data/cresci2017/social_spambots_3.csv\")\n",
    "ts1 = pd.read_csv(\"data/cresci2017/traditional_spambots_1.csv\")\n",
    "ts2 = pd.read_csv(\"data/cresci2017/traditional_spambots_2.csv\")\n",
    "ts3 = pd.read_csv(\"data/cresci2017/traditional_spambots_3.csv\")\n",
    "ts4 = pd.read_csv(\"data/cresci2017/traditional_spambots_4.csv\")\n",
    "\n",
    "\n",
    "ga = pd.concat([ga, pd.read_csv(\"data/cresci2015/E13.csv\")], axis=0)  # real\n",
    "ff = pd.concat([ff, pd.read_csv(\"data/cresci2015/FSF.csv\")], axis=0) \n",
    "ff = pd.concat([ff, pd.read_csv(\"data/cresci2015/INT.csv\")], axis=0) \n",
    "ga = pd.concat([ga, pd.read_csv(\"data/cresci2015/TFP.csv\")], axis=0)  # real\n",
    "ff = pd.concat([ff, pd.read_csv(\"data/cresci2015/TWT.csv\")], axis=0) \n",
    "\n",
    "REAL_ACCOUNT = 0\n",
    "FAKE_FOLLOWER = 1\n",
    "POLITICAL_SPAMMERS = 2\n",
    "ADVERTISING_SPAMMERS = 3\n",
    "OTHER_SPAMMERS = 4\n",
    "SCAMMERS = 5\n",
    "\n",
    "def gettype(id):\n",
    "    \n",
    "    if id in list(ff.id):\n",
    "        return FAKE_FOLLOWER\n",
    "\n",
    "    elif id in list(ga.id):\n",
    "        return REAL_ACCOUNT\n",
    "\n",
    "    elif id in list(ss1.id):\n",
    "        return POLITICAL_SPAMMERS\n",
    "    elif id in list(ss2.id):\n",
    "        return ADVERTISING_SPAMMERS\n",
    "    elif id in list(ss3.id):\n",
    "        return ADVERTISING_SPAMMERS\n",
    "\n",
    "    elif id in list(ts1.id):\n",
    "        return OTHER_SPAMMERS\n",
    "    elif id in list(ts2.id):\n",
    "        return SCAMMERS\n",
    "    elif id in list(ts3.id):\n",
    "        return ADVERTISING_SPAMMERS\n",
    "    elif id in list(ts4.id):\n",
    "        return ADVERTISING_SPAMMERS\n",
    "\n",
    "    else:\n",
    "        print(id)\n",
    "        return -1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa66bcc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:18.922632Z",
     "start_time": "2022-11-13T07:20:18.919054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettype(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70ae3c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:25.600311Z",
     "start_time": "2022-11-13T07:20:18.923414Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"account_type_multi\"] = train_df[\"id\"].apply(lambda id: gettype(id))\n",
    "test_df[\"account_type_multi\"] = test_df[\"id\"].apply(lambda id: gettype(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc96ec66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:25.604089Z",
     "start_time": "2022-11-13T07:20:25.601169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"account_type_multi\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06939c32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:25.607691Z",
     "start_time": "2022-11-13T07:20:25.604971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 4, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"account_type_multi\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b960079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:20:33.830330Z",
     "start_time": "2022-11-13T07:20:25.608445Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/twitter_data_train_multiclass.csv\")\n",
    "test_df.to_csv(\"data/twitter_data_test_multiclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71534a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "77238a471535228e8cd55a3ca9e771a69c6c0bc66c44a56c972f9554a4042742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
