{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66f02fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:22.788933Z",
     "start_time": "2022-11-13T06:56:22.777028Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae51145",
   "metadata": {},
   "source": [
    "<h1>Import Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f3c7878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:22.795241Z",
     "start_time": "2022-11-13T06:56:22.792138Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \"data/\"\n",
    "has_face_pkl_path = \"data/has_face.pkl\"\n",
    "reciprocity_path = \"data/reciprocity.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ebfa370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:26.484782Z",
     "start_time": "2022-11-13T06:56:22.796886Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(base + \"/combined_twitter_data_with_tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d60d3810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:56:26.491765Z",
     "start_time": "2022-11-13T06:56:26.485735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'name', 'screen_name',\n",
       "       'statuses_count', 'followers_count', 'friends_count',\n",
       "       'favourites_count', 'listed_count', 'url', 'lang', 'time_zone',\n",
       "       'location', 'default_profile', 'default_profile_image', 'geo_enabled',\n",
       "       'profile_image_url', 'profile_banner_url',\n",
       "       'profile_use_background_image', 'profile_background_image_url_https',\n",
       "       'profile_text_color', 'profile_image_url_https',\n",
       "       'profile_sidebar_border_color', 'profile_background_tile',\n",
       "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
       "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
       "       'protected', 'verified', 'description', 'created_at', 'updated',\n",
       "       'account_type', 'tweets_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da878038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:04.203576Z",
     "start_time": "2022-11-13T06:56:26.494728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:21: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:23: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:23: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_21712\\2429800940.py:23: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
     ]
    }
   ],
   "source": [
    "# get tweets df\n",
    "# save tweets dataset into local \n",
    "filenames_tweets = [\n",
    "    \"all tweets 2017/tweets_fake_followers.csv\",\n",
    "    \"all tweets 2017/tweets_genuine_accounts.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_1.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_2.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_3.csv\",\n",
    "    \"all tweets 2017/tweets_traditional_spambots_1.csv\",\n",
    "\n",
    "    \"tweets 2015/tweets_E13.csv\",\n",
    "    \"tweets 2015/tweets_FSF.csv\",\n",
    "    \"tweets 2015/tweets_INT.csv\",\n",
    "    \"tweets 2015/tweets_TFP.csv\",\n",
    "    \"tweets 2015/tweets_TWT.csv\"\n",
    "]\n",
    "#filenames_tweets = map(lambda x: \"data/\"+ x, filenames_tweets)\n",
    "filenames_tweets = map(lambda x: base + x, filenames_tweets)\n",
    "for i,fn in enumerate(filenames_tweets):\n",
    "    if i == 0:\n",
    "        df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
    "    else:\n",
    "        df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fa7a831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.094349Z",
     "start_time": "2022-11-13T06:57:04.205663Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.dropna(subset = [\"user_id\"])  \n",
    "df_tweets[\"user_id\"] = df_tweets[\"user_id\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3c55f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324af6f",
   "metadata": {},
   "source": [
    "### Remove columns that are redundant\n",
    "Data is redundant in helping us with our problem statement when:\n",
    "- The data is metadata\n",
    "- There are too many unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fa513ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.099625Z",
     "start_time": "2022-11-13T06:57:12.096584Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_list = ['Unnamed: 0.1', 'Unnamed: 0', 'lang', 'time_zone', 'location', 'profile_banner_url', 'profile_background_image_url_https',\n",
    "       'profile_text_color', 'profile_image_url_https', 'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
    "       'profile_background_image_url', 'profile_background_color', 'profile_link_color', 'utc_offset', 'created_at', 'updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0009e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.127707Z",
     "start_time": "2022-11-13T06:57:12.100893Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop(remove_list, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd05b0",
   "metadata": {},
   "source": [
    "### Replace NaN values with zeros for binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "624f87a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.134439Z",
     "start_time": "2022-11-13T06:57:12.129044Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users['default_profile'] = df_users['default_profile'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['geo_enabled'] = df_users['geo_enabled'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['profile_use_background_image'] = df_users['profile_use_background_image'].fillna(0)\n",
    "df_users['profile_background_tile'] = df_users['profile_background_tile'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6a871",
   "metadata": {},
   "source": [
    "<h2>Train Test Split (85-15)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "540a7261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.205471Z",
     "start_time": "2022-11-13T06:57:12.135837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake    8362\n",
      "real    2751\n",
      "Name: account_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#get the target variable - real or fake account type - binary classification problem\n",
    "df_users = df_users[(df_users['account_type'] == \"real\") | (df_users['account_type'] == \"fake\")]\n",
    "print(df_users['account_type'].value_counts())\n",
    "df_users['account_type'] = df_users['account_type'].apply(lambda x: 0 if x==\"fake\" else 1)\n",
    "\n",
    "train, test = train_test_split(df_users, test_size=0.15, random_state=69, stratify=df_users['account_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77d646c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.209526Z",
     "start_time": "2022-11-13T06:57:12.207110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 9446\n",
      "test size 1667\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", len(train))\n",
    "print(\"test size\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b7303ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:12.214700Z",
     "start_time": "2022-11-13T06:57:12.211370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7108\n",
       "1    2338\n",
       "Name: account_type, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['account_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa59a12",
   "metadata": {},
   "source": [
    "<h2>Date Formatting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b98154f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:13.380341Z",
     "start_time": "2022-11-13T06:57:12.215773Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes around 10 min to run\n",
    "df_tweets['created_at_formatted'] = pd.to_datetime(df_tweets['timestamp'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38598aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.539209Z",
     "start_time": "2022-11-13T06:57:13.383166Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets['created_at_date'] = df_tweets['created_at_formatted'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4398af",
   "metadata": {},
   "source": [
    "<h2>Tweet features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03f36ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.543885Z",
     "start_time": "2022-11-13T06:57:19.540132Z"
    }
   },
   "outputs": [],
   "source": [
    "def tweet_freq(df_users, df_tweets):\n",
    "    \n",
    "    # user tweet frequency = total number of tweets / number of user active days \n",
    "    # shows how often the user tweets among the days that a user tweets at least once. User activity is defined by whether the user tweets in a given day\n",
    "    # 1 = user tweets only once per active day \n",
    "    # >1 = user tweets more than once a day on average, in the days that the user is active \n",
    "\n",
    "    df_tweets_per_day = df_tweets.groupby(by=[\"user_id\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                              date_count=('created_at_date', lambda x: x.nunique()))\n",
    "\n",
    "    dict_tweets_average = {user_id: df_tweets_per_day.loc[user_id]['tweet_count'] / df_tweets_per_day.loc[user_id]['date_count'] for user_id in df_tweets_per_day.index}\n",
    "    #create new column for user tweet frequency \n",
    "    df_users['tweet_frequency'] = df_users['id'].map(dict_tweets_average)\n",
    "    df_users['tweet_frequency'] = df_users['tweet_frequency'].fillna(0)\n",
    "    return df_users\n",
    "\n",
    "def tweet_tags_mention(df_users, df_tweets):\n",
    "    # average number of tags per post = total number of tags used per tweet \n",
    "    # average number of mentions per post = total number of mentions per tweet \n",
    "\n",
    "    df_tweets['text'] = df_tweets['text'].apply(str) #convert all text to string\n",
    "    df_tweets['number_of_tags'] = df_tweets['text'].apply(lambda x: x.count(\"#\"))\n",
    "    df_tweets['number_of_mentions'] = df_tweets['text'].apply(lambda x: x.count(\"@\"))\n",
    "    tags_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_tags'].sum().to_dict()\n",
    "    mentions_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_mentions'].sum().to_dict() \n",
    "\n",
    "    #create new column for number of tags\n",
    "    df_users['number_of_tags'] = df_users['id'].map(tags_dict)\n",
    "    #create new column for number of mentions\n",
    "    df_users['number_of_mentions'] = df_users['id'].map(mentions_dict)\n",
    "    \n",
    "    df_users['number_of_mentions'] = df_users['number_of_mentions'].fillna(0)\n",
    "    df_users['number_of_tags'] = df_users['number_of_tags'].fillna(0)\n",
    "    return df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d082f56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.548167Z",
     "start_time": "2022-11-13T06:57:19.544776Z"
    }
   },
   "outputs": [],
   "source": [
    "# return 0 if weekend, 1 if weekday \n",
    "def is_weekday(dt):\n",
    "    return 0 if dt.weekday() > 4 else 1\n",
    "\n",
    "# return day of week \n",
    "def get_weekday(dt):\n",
    "    return dt.weekday()\n",
    "\n",
    "def get_weekend_weekday_frequency(df_tweets, df_users):\n",
    "    df_tweets['weekday'] = df_tweets['created_at_formatted'].apply(lambda x: is_weekday(x))\n",
    "    df_tweets_weekday_weekend = df_tweets.groupby(by=[\"user_id\", \"weekday\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                          date_count=('created_at_date', lambda x: x.nunique()))\n",
    "    dict_tweets_weekend = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 0}\n",
    "    df_users['tweet_weekend_frequency'] = df_users['id'].map(dict_tweets_weekend)        \n",
    "    dict_tweets_weekday = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 1}\n",
    "    df_users['tweet_weekday_frequency'] = df_users['id'].map(dict_tweets_weekday)\n",
    "    \n",
    "    df_users['tweet_weekend_frequency'] = df_users['tweet_weekend_frequency'].fillna(0)\n",
    "    df_users['tweet_weekday_frequency'] = df_users['tweet_weekday_frequency'].fillna(0)\n",
    "    return df_users      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d1618",
   "metadata": {},
   "source": [
    "<h2>Followers To Following Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "828f63cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.551329Z",
     "start_time": "2022-11-13T06:57:19.548932Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_followers_following_ratio(df):\n",
    "    #followers divide by following (high means popular, low means more following)\n",
    "    df['following_to_followers_ratio'] = df['friends_count'] / df['followers_count']\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].fillna(0)\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].apply(lambda x: 1 if x == np.inf else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857742c6",
   "metadata": {},
   "source": [
    "<h2>Name Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8cc2904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.555071Z",
     "start_time": "2022-11-13T06:57:19.552182Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_features(df):\n",
    "    #get length of username and screen name\n",
    "    df['username_length'] = df['name'].apply(lambda x: len(str(x)))\n",
    "    df['screen_name_length'] = df['screen_name'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    #anything that is not a-z or 0-9 will be blocked, outputs length\n",
    "    df['username_spec_char_count'] = df['name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    df['screen_name_spec_char_count'] = df['screen_name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ded964",
   "metadata": {},
   "source": [
    "<h2>Has URL Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f26a4f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.558576Z",
     "start_time": "2022-11-13T06:57:19.556222Z"
    }
   },
   "outputs": [],
   "source": [
    "def has_url_feature(df):\n",
    "    #1 if has url, 0 if no url\n",
    "    df['has_url'] = df['url'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463fa9a",
   "metadata": {},
   "source": [
    "<h2>Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eff62399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.563004Z",
     "start_time": "2022-11-13T06:57:19.559583Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_texts(df):\n",
    "    def process_tweets_list(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for tweet_list in corpus:\n",
    "            tweet_list = str(tweet_list)\n",
    "            row_processed = \"\"\n",
    "            \n",
    "            #replace RT and @\n",
    "            row_processed = tweet_list.replace(\"RT\", \"\" ) \n",
    "            row_processed = row_processed.replace(\"@\", \"\" )\n",
    "            \n",
    "            row_processed = re.sub(r'http\\S+', \"\", row_processed) #remove any URLs in tweets\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row_processed) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "\n",
    "        return corpus_processed\n",
    "    \n",
    "    def process_description(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for row in corpus:\n",
    "            row = str(row)\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "        return corpus_processed\n",
    "    \n",
    "    df[\"tweets_list_processed\"] = process_tweets_list(df[\"tweets_list\"])\n",
    "    df[\"description_processed\"] = process_description(df[\"description\"])\n",
    "    \n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cac20b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.566517Z",
     "start_time": "2022-11-13T06:57:19.564172Z"
    }
   },
   "outputs": [],
   "source": [
    "class LemmatizeTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, text):\n",
    "        return [self.lemmatizer.lemmatize(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfaf4de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.592461Z",
     "start_time": "2022-11-13T06:57:19.587339Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_nlp_features(df):\n",
    "\n",
    "    tfidf_feature_names = {}\n",
    "\n",
    "    max_tfidf_features = 100\n",
    "    \n",
    "    #tweets\n",
    "    vect_tweets = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=max_tfidf_features, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    tweets_processed = pd.Series(df[\"tweets_list_processed\"])\n",
    "    tfidf_fit_tweets = vect_tweets.fit(tweets_processed)\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(tweets_processed).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x: \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    tfidf_feature_names[\"tweets\"] = list(zip(range(max_tfidf_features),vect_tweets.get_feature_names()))\n",
    "    \n",
    "    #description\n",
    "    vect_description = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=max_tfidf_features, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    description_processed = pd.Series(df[\"description_processed\"])\n",
    "    tfidf_fit_description = vect_description.fit(description_processed)\n",
    "    description_tfidf_array = tfidf_fit_description.transform(description_processed).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x: \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    tfidf_feature_names[\"description\"] = list(zip(range(max_tfidf_features),vect_description.get_feature_names()))\n",
    "\n",
    "\n",
    "    \n",
    "    return (df, tfidf_fit_tweets, tfidf_fit_description, tfidf_feature_names)\n",
    "\n",
    "def nlp_transform_test(df, tfidf_fit_tweets, tfidf_fit_description):\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(df['tweets_list_processed']).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x : \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    description_tfidf_array = tfidf_fit_description.transform(df['description_processed']).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x : \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282b893",
   "metadata": {},
   "source": [
    "## Has Face Feature (Face Detection with MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68e485e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.599299Z",
     "start_time": "2022-11-13T06:57:19.593608Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the mapping and attach to df during combine\n",
    "with open(has_face_pkl_path, 'rb') as f:\n",
    "    has_face_d = pickle.load(f)\n",
    "\n",
    "has_face_d = {int(k):v for k,v in has_face_d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13d25e",
   "metadata": {},
   "source": [
    "## Graph Analysis: Reciprocity of each user \n",
    "- The ratio of the number of relations which are reciprocated over the total number of relations in a directed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fbf40d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T06:57:19.603244Z",
     "start_time": "2022-11-13T06:57:19.600188Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the mapping and attach to df during combine\n",
    "with open(reciprocity_path, 'rb') as f:\n",
    "    reci_d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4ac4b",
   "metadata": {},
   "source": [
    "<h2>Combine all Feature Generating Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ff95beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:13:18.234385Z",
     "start_time": "2022-11-13T06:57:19.604172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\valen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "result = tweet_freq(train, df_tweets)\n",
    "result = tweet_tags_mention(result, df_tweets)\n",
    "result = get_weekend_weekday_frequency(df_tweets, result)\n",
    "result = create_followers_following_ratio(result)\n",
    "result = name_features(result)\n",
    "result = has_url_feature(result)\n",
    "result = clean_texts(result)\n",
    "result, tfidf_fit_tweets, tfidf_fit_description, tfidf_feature_names = generate_nlp_features(result)\n",
    "result['has_face'] = result['id'].map(has_face_d)\n",
    "result['reciprocity'] = result['id'].map(reci_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "615aeb44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:13:18.298031Z",
     "start_time": "2022-11-13T07:13:18.236126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82118682</td>\n",
       "      <td>davide gazzÃ¨</td>\n",
       "      <td>davidegazze</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1174756808</td>\n",
       "      <td>Carolee Moberly</td>\n",
       "      <td>MoberlycikCarol</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>708732794</td>\n",
       "      <td>Julius Kirk</td>\n",
       "      <td>juliuskirkdoq</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360642101</td>\n",
       "      <td>Magan Skripko</td>\n",
       "      <td>MaganSkripko</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2379608905</td>\n",
       "      <td>Martin Bruley</td>\n",
       "      <td>MartinBruley</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>2363037596</td>\n",
       "      <td>Ula Banegas</td>\n",
       "      <td>UlaBanegas</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9442</th>\n",
       "      <td>1175035327</td>\n",
       "      <td>Jasmine Finkelstein</td>\n",
       "      <td>FinkelsteinupdJ</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>67631743</td>\n",
       "      <td>TMJ-Morocco Jobs</td>\n",
       "      <td>tmj_mar_jobs1</td>\n",
       "      <td>49</td>\n",
       "      <td>582</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>2370803990</td>\n",
       "      <td>Christy Schnicke</td>\n",
       "      <td>ChristySchnicke</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>2360933791</td>\n",
       "      <td>Abbey Pelaez</td>\n",
       "      <td>AbbeyPelaez</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9446 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 name      screen_name  statuses_count  \\\n",
       "0       82118682        davide gazzÃ¨      davidegazze              88   \n",
       "1     1174756808      Carolee Moberly  MoberlycikCarol              19   \n",
       "2      708732794          Julius Kirk    juliuskirkdoq              22   \n",
       "3     2360642101        Magan Skripko     MaganSkripko              47   \n",
       "4     2379608905        Martin Bruley     MartinBruley              34   \n",
       "...          ...                  ...              ...             ...   \n",
       "9441  2363037596          Ula Banegas       UlaBanegas              53   \n",
       "9442  1175035327  Jasmine Finkelstein  FinkelsteinupdJ              22   \n",
       "9443    67631743     TMJ-Morocco Jobs    tmj_mar_jobs1              49   \n",
       "9444  2370803990     Christy Schnicke  ChristySchnicke              64   \n",
       "9445  2360933791         Abbey Pelaez      AbbeyPelaez              35   \n",
       "\n",
       "      followers_count  friends_count  favourites_count  listed_count  \\\n",
       "0                  19             39                 9             0   \n",
       "1                   7            192                 0             0   \n",
       "2                  11            241                 0             0   \n",
       "3                   6             41                 0             0   \n",
       "4                   4             36                 0             0   \n",
       "...               ...            ...               ...           ...   \n",
       "9441                6             36                 0             0   \n",
       "9442                8            194                 0             0   \n",
       "9443              582            494                 0            53   \n",
       "9444               11             43                 0             0   \n",
       "9445                7             42                 0             0   \n",
       "\n",
       "                          url  default_profile  ...  description_92  \\\n",
       "0                         NaN              0.0  ...             0.0   \n",
       "1                         NaN              1.0  ...             0.0   \n",
       "2                         NaN              1.0  ...             0.0   \n",
       "3                         NaN              0.0  ...             0.0   \n",
       "4                         NaN              0.0  ...             0.0   \n",
       "...                       ...              ...  ...             ...   \n",
       "9441                      NaN              0.0  ...             0.0   \n",
       "9442                      NaN              1.0  ...             0.0   \n",
       "9443  https://t.co/DByWt45HZj              0.0  ...             0.0   \n",
       "9444                      NaN              0.0  ...             0.0   \n",
       "9445                      NaN              0.0  ...             0.0   \n",
       "\n",
       "      description_93 description_94  description_95  description_96  \\\n",
       "0                0.0            0.0             0.0             0.0   \n",
       "1                0.0            0.0             0.0             0.0   \n",
       "2                0.0            0.0             0.0             0.0   \n",
       "3                0.0            0.0             0.0             0.0   \n",
       "4                0.0            0.0             0.0             0.0   \n",
       "...              ...            ...             ...             ...   \n",
       "9441             0.0            0.0             0.0             0.0   \n",
       "9442             0.0            0.0             0.0             0.0   \n",
       "9443             0.0            0.0             0.0             0.0   \n",
       "9444             0.0            0.0             0.0             0.0   \n",
       "9445             0.0            0.0             0.0             0.0   \n",
       "\n",
       "      description_97  description_98 description_99  has_face reciprocity  \n",
       "0                0.0             0.0            0.0         1        0.75  \n",
       "1                0.0             0.0            0.0         1        0.00  \n",
       "2                0.0             0.0            0.0         1        0.00  \n",
       "3                0.0             0.0            0.0         1        0.00  \n",
       "4                0.0             0.0            0.0         1        0.00  \n",
       "...              ...             ...            ...       ...         ...  \n",
       "9441             0.0             0.0            0.0         1        0.00  \n",
       "9442             0.0             0.0            0.0         1        0.00  \n",
       "9443             0.0             0.0            0.0         0        0.00  \n",
       "9444             0.0             0.0            0.0         1        0.00  \n",
       "9445             0.0             0.0            0.0         0        0.00  \n",
       "\n",
       "[9446 rows x 235 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6ad70",
   "metadata": {},
   "source": [
    "## Apply same feature engineering on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bae570c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:25.516972Z",
     "start_time": "2022-11-13T07:13:18.304064Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tweet_freq(test, df_tweets)\n",
    "test = tweet_tags_mention(test, df_tweets)\n",
    "test = get_weekend_weekday_frequency(df_tweets, test)\n",
    "test = create_followers_following_ratio(test)\n",
    "test = name_features(test)\n",
    "test = has_url_feature(test)\n",
    "test = clean_texts(test)\n",
    "test = nlp_transform_test(test, tfidf_fit_tweets, tfidf_fit_description)\n",
    "test['has_face'] = test['id'].map(has_face_d)\n",
    "test['reciprocity'] = test['id'].map(reci_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39cb1d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:25.521120Z",
     "start_time": "2022-11-13T07:14:25.518212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "print(len(test.columns))\n",
    "print(len(result.columns))\n",
    "\n",
    "for i in result.columns:\n",
    "    if i not in test.columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d477bd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:25.534853Z",
     "start_time": "2022-11-13T07:14:25.521902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1667.000000\n",
       "mean        0.041574\n",
       "std         0.073182\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.057944\n",
       "max         0.602594\n",
       "Name: tweets_99, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tweets_99.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e4e13",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a095632b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.855311Z",
     "start_time": "2022-11-13T07:14:25.536083Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"data/twitter_data_train.csv\", index=False)\n",
    "test.to_csv(\"data/twitter_data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48bd5870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.867642Z",
     "start_time": "2022-11-13T07:14:33.856236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, tweets_66, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 235 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08957afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T07:14:33.875814Z",
     "start_time": "2022-11-13T07:14:33.868913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "      <th>reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, tweets_66, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 235 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2986687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tfidf_feature_names\n",
    "\n",
    "with open('data/tfidf_feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_feature_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "196a2188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweets': [(0, 'al'),\n",
       "  (1, 'always'),\n",
       "  (2, 'amp'),\n",
       "  (3, 'anche'),\n",
       "  (4, 'back'),\n",
       "  (5, 'best'),\n",
       "  (6, 'cant'),\n",
       "  (7, 'che'),\n",
       "  (8, 'check'),\n",
       "  (9, 'chi'),\n",
       "  (10, 'ci'),\n",
       "  (11, 'come'),\n",
       "  (12, 'con'),\n",
       "  (13, 'cool'),\n",
       "  (14, 'da'),\n",
       "  (15, 'day'),\n",
       "  (16, 'de'),\n",
       "  (17, 'dei'),\n",
       "  (18, 'del'),\n",
       "  (19, 'della'),\n",
       "  (20, 'di'),\n",
       "  (21, 'dont'),\n",
       "  (22, 'e'),\n",
       "  (23, 'essere'),\n",
       "  (24, 'get'),\n",
       "  (25, 'gli'),\n",
       "  (26, 'go'),\n",
       "  (27, 'going'),\n",
       "  (28, 'good'),\n",
       "  (29, 'got'),\n",
       "  (30, 'great'),\n",
       "  (31, 'great introduction'),\n",
       "  (32, 'ha'),\n",
       "  (33, 'history'),\n",
       "  (34, 'ho'),\n",
       "  (35, 'il'),\n",
       "  (36, 'im'),\n",
       "  (37, 'introduction'),\n",
       "  (38, 'io'),\n",
       "  (39, 'know'),\n",
       "  (40, 'la'),\n",
       "  (41, 'le'),\n",
       "  (42, 'learn'),\n",
       "  (43, 'life'),\n",
       "  (44, 'like'),\n",
       "  (45, 'lo'),\n",
       "  (46, 'lol'),\n",
       "  (47, 'look'),\n",
       "  (48, 'love'),\n",
       "  (49, 'mai'),\n",
       "  (50, 'make'),\n",
       "  (51, 'man'),\n",
       "  (52, 'mi'),\n",
       "  (53, 'money'),\n",
       "  (54, 'much'),\n",
       "  (55, 'na'),\n",
       "  (56, 'need'),\n",
       "  (57, 'never'),\n",
       "  (58, 'new'),\n",
       "  (59, 'non'),\n",
       "  (60, 'one'),\n",
       "  (61, 'people'),\n",
       "  (62, 'per'),\n",
       "  (63, 'perch'),\n",
       "  (64, 'pi'),\n",
       "  (65, 'quando'),\n",
       "  (66, 'read'),\n",
       "  (67, 'read history'),\n",
       "  (68, 'really'),\n",
       "  (69, 'right'),\n",
       "  (70, 'say'),\n",
       "  (71, 'se'),\n",
       "  (72, 'see'),\n",
       "  (73, 'sempre'),\n",
       "  (74, 'shoe'),\n",
       "  (75, 'si'),\n",
       "  (76, 'solo'),\n",
       "  (77, 'something'),\n",
       "  (78, 'sono'),\n",
       "  (79, 'su'),\n",
       "  (80, 'take'),\n",
       "  (81, 'te'),\n",
       "  (82, 'thing'),\n",
       "  (83, 'think'),\n",
       "  (84, 'ti'),\n",
       "  (85, 'time'),\n",
       "  (86, 'today'),\n",
       "  (87, 'tutti'),\n",
       "  (88, 'twitter'),\n",
       "  (89, 'u'),\n",
       "  (90, 'un'),\n",
       "  (91, 'una'),\n",
       "  (92, 'via'),\n",
       "  (93, 'wa'),\n",
       "  (94, 'want'),\n",
       "  (95, 'way'),\n",
       "  (96, 'work'),\n",
       "  (97, 'world'),\n",
       "  (98, 'would'),\n",
       "  (99, 'youre')],\n",
       " 'description': [(0, '2'),\n",
       "  (1, 'account'),\n",
       "  (2, 'account geotargeted'),\n",
       "  (3, 'account geotargeted businessmgmt'),\n",
       "  (4, 'account geotargeted customer'),\n",
       "  (5, 'account geotargeted job'),\n",
       "  (6, 'back'),\n",
       "  (7, 'blog'),\n",
       "  (8, 'business'),\n",
       "  (9, 'businessmgmt'),\n",
       "  (10, 'businessmgmt job'),\n",
       "  (11, 'businessmgmt job tweet'),\n",
       "  (12, 'careerarc'),\n",
       "  (13, 'che'),\n",
       "  (14, 'click'),\n",
       "  (15, 'click link'),\n",
       "  (16, 'code'),\n",
       "  (17, 'customer'),\n",
       "  (18, 'customer service'),\n",
       "  (19, 'customer service job'),\n",
       "  (20, 'da'),\n",
       "  (21, 'de'),\n",
       "  (22, 'di'),\n",
       "  (23, 'dont'),\n",
       "  (24, 'e'),\n",
       "  (25, 'enter'),\n",
       "  (26, 'fan'),\n",
       "  (27, 'follow'),\n",
       "  (28, 'follow account'),\n",
       "  (29, 'follow account geotargeted'),\n",
       "  (30, 'friend'),\n",
       "  (31, 'geotargeted'),\n",
       "  (32, 'geotargeted businessmgmt'),\n",
       "  (33, 'geotargeted businessmgmt job'),\n",
       "  (34, 'geotargeted customer'),\n",
       "  (35, 'geotargeted customer service'),\n",
       "  (36, 'geotargeted job'),\n",
       "  (37, 'geotargeted job tweet'),\n",
       "  (38, 'get'),\n",
       "  (39, 'help'),\n",
       "  (40, 'help tweet'),\n",
       "  (41, 'help tweet u'),\n",
       "  (42, 'hiring'),\n",
       "  (43, 'il'),\n",
       "  (44, 'im'),\n",
       "  (45, 'java'),\n",
       "  (46, 'job'),\n",
       "  (47, 'job tweet'),\n",
       "  (48, 'know'),\n",
       "  (49, 'la'),\n",
       "  (50, 'le'),\n",
       "  (51, 'life'),\n",
       "  (52, 'like'),\n",
       "  (53, 'link'),\n",
       "  (54, 'love'),\n",
       "  (55, 'lover'),\n",
       "  (56, 'make'),\n",
       "  (57, 'medium'),\n",
       "  (58, 'member'),\n",
       "  (59, 'member twitter'),\n",
       "  (60, 'mi'),\n",
       "  (61, 'music'),\n",
       "  (62, 'need'),\n",
       "  (63, 'need help'),\n",
       "  (64, 'need help tweet'),\n",
       "  (65, 'new'),\n",
       "  (66, 'non'),\n",
       "  (67, 'nonmetro'),\n",
       "  (68, 'nonmetro need'),\n",
       "  (69, 'nonmetro need help'),\n",
       "  (70, 'one'),\n",
       "  (71, 'open'),\n",
       "  (72, 'people'),\n",
       "  (73, 'per'),\n",
       "  (74, 'prize'),\n",
       "  (75, 'que'),\n",
       "  (76, 'resource'),\n",
       "  (77, 'se'),\n",
       "  (78, 'service'),\n",
       "  (79, 'service job'),\n",
       "  (80, 'service job tweet'),\n",
       "  (81, 'site'),\n",
       "  (82, 'social'),\n",
       "  (83, 'social medium'),\n",
       "  (84, 'software'),\n",
       "  (85, 'time'),\n",
       "  (86, 'tweet'),\n",
       "  (87, 'tweet u'),\n",
       "  (88, 'tweet u careerarc'),\n",
       "  (89, 'twitter'),\n",
       "  (90, 'u'),\n",
       "  (91, 'u careerarc'),\n",
       "  (92, 'un'),\n",
       "  (93, 'una'),\n",
       "  (94, 'unique'),\n",
       "  (95, 'web'),\n",
       "  (96, 'winner'),\n",
       "  (97, 'winner unique'),\n",
       "  (98, 'world'),\n",
       "  (99, 'writer')]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab0ca096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  NaN\n",
       "1    Spirit Led Conservative news blogger. #TeamJes...\n",
       "2                                                  NaN\n",
       "3                                                  NaN\n",
       "4                                                  NaN\n",
       "5                                                  NaN\n",
       "6    ProvidingFREE information on How To Create A W...\n",
       "7                        L'azzurro Ã¨ un cognome, sÃ¬.\n",
       "8                         Seahawks, Mariners, #gohawks\n",
       "9    Shitspeak from @Fantattitude so @ldesroziers d...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['description']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "77238a471535228e8cd55a3ca9e771a69c6c0bc66c44a56c972f9554a4042742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
