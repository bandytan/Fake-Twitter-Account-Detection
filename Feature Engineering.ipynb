{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63706808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329d8c6",
   "metadata": {},
   "source": [
    "<h1>Import Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f867c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(\"./data/combined_twitter_data_with_tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acffc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweets df\n",
    "# save tweets dataset into local \n",
    "filenames_tweets = [\n",
    "    \"data/all tweets 2017/tweets_fake_followers.csv\",\n",
    "    \"data/all tweets 2017/tweets_genuine_accounts.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_1.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_2.csv\",\n",
    "    \"data/all tweets 2017/tweets_social_spambots_3.csv\",\n",
    "    \"data/all tweets 2017/tweets_traditional_spambots_1.csv\",\n",
    "\n",
    "    \"data/tweets 2015/tweets_E13.csv\",\n",
    "    \"data/tweets 2015/tweets_FSF.csv\",\n",
    "    \"data/tweets 2015/tweets_INT.csv\",\n",
    "    \"data/tweets 2015/tweets_TFP.csv\",\n",
    "    \"data/tweets 2015/tweets_TWT.csv\"\n",
    "]\n",
    "\n",
    "for i,fn in enumerate(filenames_tweets):\n",
    "    if i == 0:\n",
    "        df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
    "    else:\n",
    "        df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ef07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.dropna(subset = [\"user_id\"])  \n",
    "df_tweets[\"user_id\"] = df_tweets[\"user_id\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfbd4fb",
   "metadata": {},
   "source": [
    "<h2>Train Test Split (70-15-15)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the target variable - real or fake account type - binary classification problem\n",
    "df_users = df_users[(df_users['account_type'] == \"real\") | (df_users['account_type'] == \"fake\")]\n",
    "print(df_users['account_type'].value_counts())\n",
    "df_users['account_type'] = df_users['account_type'].apply(lambda x: 0 if x==\"fake\" else 1)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.15, random_state=69, stratify=df['account_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c124b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size:\", len(train))\n",
    "print(\"test size\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['account_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010d79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c60a6978",
   "metadata": {},
   "source": [
    "<h2>Date Formatting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 10 min to run\n",
    "df_users_train['created_at_formatted'] = pd.to_datetime(df_tweets['timestamp'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['created_at_date'] = df_train['created_at_formatted'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32fe7c",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918afe",
   "metadata": {},
   "source": [
    "## User tweet frequency, tags and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ecd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_freq(df):\n",
    "    # user tweet frequency = total number of tweets / number of user active days \n",
    "    # shows how often the user tweets among the days that a user tweets at least once. User activity is defined by whether the user tweets in a given day\n",
    "    # 1 = user tweets only once per active day \n",
    "    # >1 = user tweets more than once a day on average, in the days that the user is active \n",
    "    \n",
    "    df_tweets_per_day = df.groupby(by=[\"user_id\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                          date_count=('created_at_date', lambda x: x.nunique()))\n",
    "    dict_tweets_average = {user_id: df_tweets_per_day.loc[user_id]['tweet_count'] / df_tweets_per_day.loc[user_id]['date_count'] for user_id in df_tweets_per_day.index}\n",
    "    \n",
    "    \n",
    "    #create new column for user tweet frequency\n",
    "    df['tweet_frequency'] = df['id'].map(dict_tweets_average)\n",
    "    \n",
    "    # average number of tags per post = total number of tags used per tweet \n",
    "    # average number of mentions per post = total number of mentions per tweet \n",
    "\n",
    "    df['text'] = df['text'].apply(str) #convert all text to string\n",
    "    df['number_of_tags'] = df['text'].apply(lambda x: x.count(\"#\"))\n",
    "    df['number_of_mentions'] = df['text'].apply(lambda x: x.count(\"@\"))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd92ed",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/twitter_data_train.csv\", index=False)\n",
    "test.to_csv(\"data/twitter_data_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
