{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, roc_curve, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import eli5\n",
    "from lime import lime_tabular\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9446, 237)\n(1667, 237)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/twitter_data_train_multiclass.csv\")\n",
    "test_df = pd.read_csv(\"data/twitter_data_test_multiclass.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'Unnamed: 0',\n",
    "    'account_type', \n",
    "    'account_type_multi',\n",
    "    'id', \n",
    "    'name', \n",
    "    'screen_name',\n",
    "    'profile_image_url',\n",
    "    'protected',\n",
    "    'verified',\n",
    "    'description',\n",
    "    'description_processed',\n",
    "    'tweets_list',\n",
    "    'tweets_list_processed',\n",
    "    'url',\n",
    "    'profile_use_background_image', \n",
    "    'profile_background_tile'\n",
    "    ]\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "train_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']] = scaler.fit_transform(train_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']])\n",
    "test_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']] = scaler.transform(test_df[['statuses_count', 'favourites_count', 'followers_count', 'friends_count', 'number_of_mentions', 'listed_count', 'number_of_tags']])\n",
    "\n",
    "X_train, y_train = train_df.drop(to_drop, axis=1), train_df['account_type_multi']\n",
    "X_test, y_test = test_df.drop(to_drop, axis=1), test_df['account_type_multi']\n",
    "\n",
    "# validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "y_test_cat  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                14208     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,044\n",
      "Trainable params: 23,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.5368 - acc: 0.8226 - val_loss: 0.2188 - val_acc: 0.9442\n",
      "Epoch 2/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.2225 - acc: 0.9370 - val_loss: 0.1796 - val_acc: 0.9506\n",
      "Epoch 3/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1589 - acc: 0.9580 - val_loss: 0.1226 - val_acc: 0.9605\n",
      "Epoch 4/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9649 - val_loss: 0.1290 - val_acc: 0.9626\n",
      "Epoch 5/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1052 - acc: 0.9676 - val_loss: 0.1196 - val_acc: 0.9598\n",
      "Epoch 6/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1022 - acc: 0.9716 - val_loss: 0.1096 - val_acc: 0.9682\n",
      "Epoch 7/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9740 - val_loss: 0.1196 - val_acc: 0.9626\n",
      "Epoch 8/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.0840 - acc: 0.9753 - val_loss: 0.1070 - val_acc: 0.9718\n",
      "Epoch 9/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0731 - acc: 0.9782 - val_loss: 0.1023 - val_acc: 0.9732\n",
      "Epoch 10/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.0594 - acc: 0.9827 - val_loss: 0.1305 - val_acc: 0.9584\n",
      "Epoch 11/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0712 - acc: 0.9792 - val_loss: 0.1441 - val_acc: 0.9654\n",
      "Epoch 12/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0691 - acc: 0.9797 - val_loss: 0.1271 - val_acc: 0.9633\n",
      "Epoch 13/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.0566 - acc: 0.9811 - val_loss: 0.1104 - val_acc: 0.9725\n",
      "Epoch 14/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.0621 - acc: 0.9823 - val_loss: 0.1193 - val_acc: 0.9689\n",
      "Epoch 15/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0619 - acc: 0.9843 - val_loss: 0.1158 - val_acc: 0.9668\n",
      "Epoch 16/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0538 - acc: 0.9829 - val_loss: 0.0994 - val_acc: 0.9711\n",
      "Epoch 17/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0562 - acc: 0.9829 - val_loss: 0.0962 - val_acc: 0.9697\n",
      "Epoch 18/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0631 - acc: 0.9813 - val_loss: 0.1088 - val_acc: 0.9689\n",
      "Epoch 19/20\n",
      "251/251 [==============================] - 0s 2ms/step - loss: 0.0512 - acc: 0.9851 - val_loss: 0.1005 - val_acc: 0.9711\n",
      "Epoch 20/20\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.0515 - acc: 0.9852 - val_loss: 0.1145 - val_acc: 0.9697\n",
      "Total time taken for the program execution 8.75245213508606\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation = 'relu', input_dim = 221))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(X_train, y_train_cat, epochs=20, validation_data=(X_val, y_val_cat))\n",
    "\n",
    "time_taken = time.time() - start_time\n",
    "print(\"Total time taken for the program execution\", time_taken) # seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "251/251 [==============================] - 0s 707us/step\n",
      "Total time taken for the program execution 0.3873770236968994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96537   0.99597   0.98043      1987\n",
      "           1    0.99779   0.98042   0.98903      2298\n",
      "           2    0.98101   0.98569   0.98335      1258\n",
      "           3    0.99959   0.98793   0.99373      2486\n",
      "\n",
      "    accuracy                        0.98742      8029\n",
      "   macro avg    0.98594   0.98750   0.98663      8029\n",
      "weighted avg    0.98769   0.98742   0.98746      8029\n",
      "\n",
      "F1 weighted:  0.9874649341108309\n"
     ]
    }
   ],
   "source": [
    "best_clf = model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "y_pred_train = best_clf.predict(X_train)\n",
    "y_pred_train = np.argmax(y_pred_train,axis=1)\n",
    "\n",
    "time_taken = time.time() - start_time\n",
    "print(\"Total time taken for the program execution\", time_taken) # seconds\n",
    "print(classification_report(y_train, y_pred_train, digits=5))\n",
    "# roc_auc_score(y_test, y_pred_test)\n",
    "print(\"F1 weighted: \", f1_score(y_train, y_pred_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "Total time taken for the program execution 0.15932583808898926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93968   0.98063   0.95972       413\n",
      "           1    0.99119   0.97826   0.98468       460\n",
      "           2    0.97436   0.96377   0.96903       276\n",
      "           3    0.99018   0.97297   0.98150       518\n",
      "\n",
      "    accuracy                        0.97481      1667\n",
      "   macro avg    0.97385   0.97391   0.97373      1667\n",
      "weighted avg    0.97533   0.97481   0.97492      1667\n",
      "\n",
      "F1 weighted:  0.9749171608299166\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "y_pred_test = best_clf.predict(X_test)\n",
    "y_pred_test = np.argmax(y_pred_test,axis=1)\n",
    "\n",
    "time_taken = time.time() - start_time\n",
    "print(\"Total time taken for the program execution\", time_taken) # seconds\n",
    "print(classification_report(y_test, y_pred_test, digits=5))\n",
    "# roc_auc_score(y_test, y_pred_test)\n",
    "print(\"F1 weighted: \", f1_score(y_test, y_pred_test, average='weighted'))"
   ]
  },
  {
   "source": [
    "### compute SHAP values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(X_train.values, mode=\"classification\",\n",
    "                                              class_names=y_train.values,\n",
    "                                              feature_names=list(X_train.columns),\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "161/161 [==============================] - 3s 10ms/step - loss: 0.5319 - acc: 0.8240 - val_loss: 0.2595 - val_acc: 0.9308\n",
      "Epoch 2/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2278 - acc: 0.9296 - val_loss: 0.1812 - val_acc: 0.9541\n",
      "Epoch 3/20\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.1674 - acc: 0.9540 - val_loss: 0.1617 - val_acc: 0.9562\n",
      "Epoch 4/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1361 - acc: 0.9608 - val_loss: 0.1454 - val_acc: 0.9612\n",
      "Epoch 5/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.1105 - acc: 0.9679 - val_loss: 0.1571 - val_acc: 0.9555\n",
      "Epoch 6/20\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.0973 - acc: 0.9725 - val_loss: 0.1123 - val_acc: 0.9697\n",
      "Epoch 7/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.0897 - acc: 0.9733 - val_loss: 0.1136 - val_acc: 0.9732\n",
      "Epoch 8/20\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.0971 - acc: 0.9760 - val_loss: 0.1357 - val_acc: 0.9654\n",
      "Epoch 9/20\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.0782 - acc: 0.9768 - val_loss: 0.1335 - val_acc: 0.9675\n",
      "Epoch 10/20\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.0783 - acc: 0.9770 - val_loss: 0.1463 - val_acc: 0.9633\n",
      "Epoch 11/20\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.0730 - acc: 0.9801 - val_loss: 0.1106 - val_acc: 0.9689\n",
      "Epoch 12/20\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 0.0575 - acc: 0.9828 - val_loss: 0.1048 - val_acc: 0.9739\n",
      "Epoch 13/20\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.0658 - acc: 0.9812 - val_loss: 0.1110 - val_acc: 0.9718\n",
      "Epoch 14/20\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.0612 - acc: 0.9827 - val_loss: 0.1093 - val_acc: 0.9704\n",
      "Epoch 15/20\n",
      "161/161 [==============================] - 2s 12ms/step - loss: 0.0598 - acc: 0.9814 - val_loss: 0.1022 - val_acc: 0.9760\n",
      "Epoch 16/20\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 0.0609 - acc: 0.9837 - val_loss: 0.1077 - val_acc: 0.9718\n",
      "Epoch 17/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.0606 - acc: 0.9828 - val_loss: 0.1013 - val_acc: 0.9725\n",
      "Epoch 18/20\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0496 - acc: 0.9849 - val_loss: 0.1080 - val_acc: 0.9682\n",
      "Epoch 19/20\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.0511 - acc: 0.9827 - val_loss: 0.1171 - val_acc: 0.9661\n",
      "Epoch 20/20\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0476 - acc: 0.9842 - val_loss: 0.1135 - val_acc: 0.9675\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9ccd74cd0>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu', input_dim = 221))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "my_model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=50, validation_data=(X_val, y_val))\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.1362\n                \n                    &plusmn; 0.0115\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                following_to_followers_ratio\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 85.21%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0885\n                \n                    &plusmn; 0.0042\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweet_weekday_frequency\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.85%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0591\n                \n                    &plusmn; 0.0031\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweet_weekend_frequency\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 89.13%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0570\n                \n                    &plusmn; 0.0103\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweet_frequency\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 96.23%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0126\n                \n                    &plusmn; 0.0052\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                has_desc\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 96.88%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0096\n                \n                    &plusmn; 0.0060\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                geo_enabled\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.72%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0027\n                \n                    &plusmn; 0.0038\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                screen_name_spec_char_count\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.97%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0020\n                \n                    &plusmn; 0.0011\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_72\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0037\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                username_length\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0007\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_8\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.07%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0017\n                \n                    &plusmn; 0.0029\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                reciprocity\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0013\n                \n                    &plusmn; 0.0019\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                description_46\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0013\n                \n                    &plusmn; 0.0014\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_24\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0013\n                \n                    &plusmn; 0.0014\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_58\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0010\n                \n                    &plusmn; 0.0011\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_20\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0010\n                \n                    &plusmn; 0.0026\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_88\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0008\n                \n                    &plusmn; 0.0006\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                description_42\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0008\n                \n                    &plusmn; 0.0014\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_93\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0008\n                \n                    &plusmn; 0.0006\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                tweets_26\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0008\n                \n                    &plusmn; 0.0031\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                screen_name_length\n            </td>\n        </tr>\n    \n    \n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 201 more &hellip;</i>\n                </td>\n            </tr>\n        \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "perm = PermutationImportance(my_model, scoring=\"accuracy\", random_state=1).fit(X_val, y_val)\n",
    "eli5.show_weights(perm, feature_names = X_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77238a471535228e8cd55a3ca9e771a69c6c0bc66c44a56c972f9554a4042742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}