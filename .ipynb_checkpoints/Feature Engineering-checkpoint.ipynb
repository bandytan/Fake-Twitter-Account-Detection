{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f02fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:17:42.433754Z",
     "start_time": "2022-11-02T09:17:42.421695Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae51145",
   "metadata": {},
   "source": [
    "<h1>Import Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f3c7878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:18:04.784771Z",
     "start_time": "2022-11-02T09:18:04.768235Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \"/Users/ivankoh/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/1D/NUS Y3S1/BT4012/Data/\"\n",
    "has_face_pkl_path = \"/Users/ivankoh/Documents/GitHub/Fake-Twitter-Account-Detection/data/has_face.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ebfa370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:18:32.384286Z",
     "start_time": "2022-11-02T09:18:29.518007Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(base + \"/combined_twitter_data_with_tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60d3810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:18:33.603770Z",
     "start_time": "2022-11-02T09:18:33.585418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'name', 'screen_name',\n",
       "       'statuses_count', 'followers_count', 'friends_count',\n",
       "       'favourites_count', 'listed_count', 'url', 'lang', 'time_zone',\n",
       "       'location', 'default_profile', 'default_profile_image', 'geo_enabled',\n",
       "       'profile_image_url', 'profile_banner_url',\n",
       "       'profile_use_background_image', 'profile_background_image_url_https',\n",
       "       'profile_text_color', 'profile_image_url_https',\n",
       "       'profile_sidebar_border_color', 'profile_background_tile',\n",
       "       'profile_sidebar_fill_color', 'profile_background_image_url',\n",
       "       'profile_background_color', 'profile_link_color', 'utc_offset',\n",
       "       'protected', 'verified', 'description', 'created_at', 'updated',\n",
       "       'account_type', 'tweets_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da878038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:30.848308Z",
     "start_time": "2022-11-02T09:20:46.915304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:21: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:23: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:23: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n",
      "/var/folders/dq/33rpc0cx4f54t0vx2cdcgczr0000gn/T/ipykernel_65239/2429800940.py:23: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
     ]
    }
   ],
   "source": [
    "# get tweets df\n",
    "# save tweets dataset into local \n",
    "filenames_tweets = [\n",
    "    \"all tweets 2017/tweets_fake_followers.csv\",\n",
    "    \"all tweets 2017/tweets_genuine_accounts.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_1.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_2.csv\",\n",
    "    \"all tweets 2017/tweets_social_spambots_3.csv\",\n",
    "    \"all tweets 2017/tweets_traditional_spambots_1.csv\",\n",
    "\n",
    "    \"tweets 2015/tweets_E13.csv\",\n",
    "    \"tweets 2015/tweets_FSF.csv\",\n",
    "    \"tweets 2015/tweets_INT.csv\",\n",
    "    \"tweets 2015/tweets_TFP.csv\",\n",
    "    \"tweets 2015/tweets_TWT.csv\"\n",
    "]\n",
    "#filenames_tweets = map(lambda x: \"data/\"+ x, filenames_tweets)\n",
    "filenames_tweets = map(lambda x: base + x, filenames_tweets)\n",
    "for i,fn in enumerate(filenames_tweets):\n",
    "    if i == 0:\n",
    "        df_tweets = pd.read_csv(fn, encoding='ISO-8859-1')\n",
    "    else:\n",
    "        df_tweets = pd.concat([df_tweets, pd.read_csv(fn, encoding='ISO-8859-1') ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa7a831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.716288Z",
     "start_time": "2022-11-02T09:21:30.851123Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.dropna(subset = [\"user_id\"])  \n",
    "df_tweets[\"user_id\"] = df_tweets[\"user_id\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3c55f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324af6f",
   "metadata": {},
   "source": [
    "### Remove columns that are redundant\n",
    "Data is redundant in helping us with our problem statement when:\n",
    "- The data is metadata\n",
    "- There are too many unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa513ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.722005Z",
     "start_time": "2022-11-02T09:21:39.718563Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_list = ['Unnamed: 0.1', 'Unnamed: 0', 'lang', 'time_zone', 'location', 'profile_banner_url', 'profile_background_image_url_https',\n",
    "       'profile_text_color', 'profile_image_url_https', 'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
    "       'profile_background_image_url', 'profile_background_color', 'profile_link_color', 'utc_offset', 'created_at', 'updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0009e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.758584Z",
     "start_time": "2022-11-02T09:21:39.723047Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop(remove_list, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd05b0",
   "metadata": {},
   "source": [
    "### Replace NaN values with zeros for binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624f87a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.767563Z",
     "start_time": "2022-11-02T09:21:39.761196Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users['default_profile'] = df_users['default_profile'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['geo_enabled'] = df_users['geo_enabled'].fillna(0)\n",
    "df_users['default_profile_image'] = df_users['default_profile_image'].fillna(0)\n",
    "df_users['profile_use_background_image'] = df_users['profile_use_background_image'].fillna(0)\n",
    "df_users['profile_background_tile'] = df_users['profile_background_tile'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6a871",
   "metadata": {},
   "source": [
    "<h2>Train Test Split (85-15)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "540a7261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.793297Z",
     "start_time": "2022-11-02T09:21:39.769181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake    8362\n",
      "real    2751\n",
      "Name: account_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#get the target variable - real or fake account type - binary classification problem\n",
    "df_users = df_users[(df_users['account_type'] == \"real\") | (df_users['account_type'] == \"fake\")]\n",
    "print(df_users['account_type'].value_counts())\n",
    "df_users['account_type'] = df_users['account_type'].apply(lambda x: 0 if x==\"fake\" else 1)\n",
    "\n",
    "train, test = train_test_split(df_users, test_size=0.15, random_state=69, stratify=df_users['account_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d646c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.796550Z",
     "start_time": "2022-11-02T09:21:39.794545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 9446\n",
      "test size 1667\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", len(train))\n",
    "print(\"test size\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b7303ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:39.800967Z",
     "start_time": "2022-11-02T09:21:39.797594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7108\n",
       "1    2338\n",
       "Name: account_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['account_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa59a12",
   "metadata": {},
   "source": [
    "<h2>Date Formatting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b98154f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:41.055019Z",
     "start_time": "2022-11-02T09:21:39.802236Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes around 10 min to run\n",
    "df_tweets['created_at_formatted'] = pd.to_datetime(df_tweets['timestamp'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38598aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.808874Z",
     "start_time": "2022-11-02T09:21:41.056162Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets['created_at_date'] = df_tweets['created_at_formatted'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4398af",
   "metadata": {},
   "source": [
    "<h2>Tweet features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f36ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.814973Z",
     "start_time": "2022-11-02T09:21:48.810456Z"
    }
   },
   "outputs": [],
   "source": [
    "def tweet_freq(df_users, df_tweets):\n",
    "    \n",
    "    # user tweet frequency = total number of tweets / number of user active days \n",
    "    # shows how often the user tweets among the days that a user tweets at least once. User activity is defined by whether the user tweets in a given day\n",
    "    # 1 = user tweets only once per active day \n",
    "    # >1 = user tweets more than once a day on average, in the days that the user is active \n",
    "\n",
    "    df_tweets_per_day = df_tweets.groupby(by=[\"user_id\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                              date_count=('created_at_date', lambda x: x.nunique()))\n",
    "\n",
    "    dict_tweets_average = {user_id: df_tweets_per_day.loc[user_id]['tweet_count'] / df_tweets_per_day.loc[user_id]['date_count'] for user_id in df_tweets_per_day.index}\n",
    "    #create new column for user tweet frequency \n",
    "    df_users['tweet_frequency'] = df_users['id'].map(dict_tweets_average)\n",
    "    df_users['tweet_frequency'] = df_users['tweet_frequency'].fillna(0)\n",
    "    return df_users\n",
    "\n",
    "def tweet_tags_mention(df_users, df_tweets):\n",
    "    # average number of tags per post = total number of tags used per tweet \n",
    "    # average number of mentions per post = total number of mentions per tweet \n",
    "\n",
    "    df_tweets['text'] = df_tweets['text'].apply(str) #convert all text to string\n",
    "    df_tweets['number_of_tags'] = df_tweets['text'].apply(lambda x: x.count(\"#\"))\n",
    "    df_tweets['number_of_mentions'] = df_tweets['text'].apply(lambda x: x.count(\"@\"))\n",
    "    tags_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_tags'].sum().to_dict()\n",
    "    mentions_dict = df_tweets.groupby(by=[\"user_id\"])['number_of_mentions'].sum().to_dict() \n",
    "\n",
    "    #create new column for number of tags\n",
    "    df_users['number_of_tags'] = df_users['id'].map(tags_dict)\n",
    "    #create new column for number of mentions\n",
    "    df_users['number_of_mentions'] = df_users['id'].map(mentions_dict)\n",
    "    \n",
    "    df_users['number_of_mentions'] = df_users['number_of_mentions'].fillna(0)\n",
    "    df_users['number_of_tags'] = df_users['number_of_tags'].fillna(0)\n",
    "    return df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d082f56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.821381Z",
     "start_time": "2022-11-02T09:21:48.816502Z"
    }
   },
   "outputs": [],
   "source": [
    "# return 0 if weekend, 1 if weekday \n",
    "def is_weekday(dt):\n",
    "    return 0 if dt.weekday() > 4 else 1\n",
    "\n",
    "# return day of week \n",
    "def get_weekday(dt):\n",
    "    return dt.weekday()\n",
    "\n",
    "def get_weekend_weekday_frequency(df_tweets, df_users):\n",
    "    df_tweets['weekday'] = df_tweets['created_at_formatted'].apply(lambda x: is_weekday(x))\n",
    "    df_tweets_weekday_weekend = df_tweets.groupby(by=[\"user_id\", \"weekday\"]).agg(tweet_count=('text', 'count'),\n",
    "                                                          date_count=('created_at_date', lambda x: x.nunique()))\n",
    "    dict_tweets_weekend = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 0}\n",
    "    df_users['tweet_weekend_frequency'] = df_users['id'].map(dict_tweets_weekend)        \n",
    "    dict_tweets_weekday = {user_id: df_tweets_weekday_weekend.loc[(user_id, weekday)]['tweet_count'] / df_tweets_weekday_weekend.loc[(user_id, weekday)]['date_count'] for (user_id, weekday) in df_tweets_weekday_weekend.index if weekday == 1}\n",
    "    df_users['tweet_weekday_frequency'] = df_users['id'].map(dict_tweets_weekday)\n",
    "    \n",
    "    df_users['tweet_weekend_frequency'] = df_users['tweet_weekend_frequency'].fillna(0)\n",
    "    df_users['tweet_weekday_frequency'] = df_users['tweet_weekday_frequency'].fillna(0)\n",
    "    return df_users      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d1618",
   "metadata": {},
   "source": [
    "<h2>Followers To Following Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "828f63cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.825473Z",
     "start_time": "2022-11-02T09:21:48.822693Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_followers_following_ratio(df):\n",
    "    #followers divide by following (high means popular, low means more following)\n",
    "    df['following_to_followers_ratio'] = df['friends_count'] / df['followers_count']\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].fillna(0)\n",
    "    df['following_to_followers_ratio'] = df['following_to_followers_ratio'].apply(lambda x: 1 if x == np.inf else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857742c6",
   "metadata": {},
   "source": [
    "<h2>Name Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8cc2904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.831941Z",
     "start_time": "2022-11-02T09:21:48.828512Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_features(df):\n",
    "    #get length of username and screen name\n",
    "    df['username_length'] = df['name'].apply(lambda x: len(str(x)))\n",
    "    df['screen_name_length'] = df['screen_name'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    #anything that is not a-z or 0-9 will be blocked, outputs length\n",
    "    df['username_spec_char_count'] = df['name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    df['screen_name_spec_char_count'] = df['screen_name'].apply(lambda x: len(re.findall(r'[^A-Za-z0-9]+', str(x))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ded964",
   "metadata": {},
   "source": [
    "<h2>Has URL Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26a4f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.834961Z",
     "start_time": "2022-11-02T09:21:48.832998Z"
    }
   },
   "outputs": [],
   "source": [
    "def has_url_feature(df):\n",
    "    #1 if has url, 0 if no url\n",
    "    df['has_url'] = df['url'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463fa9a",
   "metadata": {},
   "source": [
    "<h2>Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff62399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.839408Z",
     "start_time": "2022-11-02T09:21:48.835867Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_texts(df):\n",
    "    def process_tweets_list(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for tweet_list in corpus:\n",
    "            tweet_list = str(tweet_list)\n",
    "            row_processed = \"\"\n",
    "            \n",
    "            #replace RT and @\n",
    "            row_processed = tweet_list.replace(\"RT\", \"\" ) \n",
    "            row_processed = row_processed.replace(\"@\", \"\" )\n",
    "            \n",
    "            row_processed = re.sub(r'http\\S+', \"\", row_processed) #remove any URLs in tweets\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row_processed) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "\n",
    "        return corpus_processed\n",
    "    \n",
    "    def process_description(corpus):\n",
    "        \n",
    "        corpus_processed = []\n",
    "        for row in corpus:\n",
    "            row = str(row)\n",
    "            row_processed = re.sub(r'[^\\x00-\\x7f]', \"\", row) #remove Non-ASCII characters\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed if not row_processed == 'nan' else \"\") # handle NA\n",
    "            \n",
    "        return corpus_processed\n",
    "    \n",
    "    df[\"tweets_list_processed\"] = process_tweets_list(df[\"tweets_list\"])\n",
    "    df[\"description_processed\"] = process_description(df[\"description\"])\n",
    "    \n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cac20b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.842711Z",
     "start_time": "2022-11-02T09:21:48.840497Z"
    }
   },
   "outputs": [],
   "source": [
    "class LemmatizeTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, text):\n",
    "        return [self.lemmatizer.lemmatize(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfaf4de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:21:48.849545Z",
     "start_time": "2022-11-02T09:21:48.843890Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_nlp_features(df):\n",
    "    \n",
    "    #tweets\n",
    "    vect_tweets = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    tweets_processed = pd.Series(df[\"tweets_list_processed\"])\n",
    "    tfidf_fit_tweets = vect_tweets.fit(tweets_processed)\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(tweets_processed).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x: \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #description\n",
    "    vect_description = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    description_processed = pd.Series(df[\"description_processed\"])\n",
    "    tfidf_fit_description = vect_description.fit(description_processed)\n",
    "    description_tfidf_array = tfidf_fit_description.transform(description_processed).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x: \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return (df, tfidf_fit_tweets, tfidf_fit_description)\n",
    "\n",
    "def nlp_transform_test(df, tfidf_fit_tweets, tfidf_fit_description):\n",
    "    tweets_tfidf_array = tfidf_fit_tweets.transform(df['tweets_list_processed']).toarray()\n",
    "    tweets_tfidf_df = pd.DataFrame(tweets_tfidf_array)\n",
    "    tweets_tfidf_df.columns = list(map(lambda x : \"tweets_\" + str(x), tweets_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),tweets_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    description_tfidf_array = tfidf_fit_description.transform(df['description_processed']).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x : \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.concat([df.reset_index(drop=True),description_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282b893",
   "metadata": {},
   "source": [
    "## Has Face Feature (Face Detection with MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68e485e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:51:43.827336Z",
     "start_time": "2022-11-02T09:51:43.802449Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the mapping and attach to df during combine\n",
    "with open(has_face_pkl_path, 'rb') as f:\n",
    "    has_face_d = pickle.load(f)\n",
    "\n",
    "has_face_d = {int(k):v for k,v in has_face_d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4ac4b",
   "metadata": {},
   "source": [
    "<h2>Combine all Feature Generating Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff95beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:42:55.265677Z",
     "start_time": "2022-11-02T09:21:48.855994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = tweet_freq(train, df_tweets)\n",
    "result = tweet_tags_mention(result, df_tweets)\n",
    "result = get_weekend_weekday_frequency(df_tweets, result)\n",
    "result = create_followers_following_ratio(result)\n",
    "result = name_features(result)\n",
    "result = has_url_feature(result)\n",
    "result = clean_texts(result)\n",
    "result, tfidf_fit_tweets, tfidf_fit_description = generate_nlp_features(result)\n",
    "result['has_face'] = result['id'].map(has_face_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "615aeb44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:42:55.318123Z",
     "start_time": "2022-11-02T09:42:55.273833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_90</th>\n",
       "      <th>description_91</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82118682</td>\n",
       "      <td>davide gazzÃ¨</td>\n",
       "      <td>davidegazze</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1174756808</td>\n",
       "      <td>Carolee Moberly</td>\n",
       "      <td>MoberlycikCarol</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>708732794</td>\n",
       "      <td>Julius Kirk</td>\n",
       "      <td>juliuskirkdoq</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2360642101</td>\n",
       "      <td>Magan Skripko</td>\n",
       "      <td>MaganSkripko</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2379608905</td>\n",
       "      <td>Martin Bruley</td>\n",
       "      <td>MartinBruley</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>2363037596</td>\n",
       "      <td>Ula Banegas</td>\n",
       "      <td>UlaBanegas</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9442</th>\n",
       "      <td>1175035327</td>\n",
       "      <td>Jasmine Finkelstein</td>\n",
       "      <td>FinkelsteinupdJ</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>67631743</td>\n",
       "      <td>TMJ-Morocco Jobs</td>\n",
       "      <td>tmj_mar_jobs1</td>\n",
       "      <td>49</td>\n",
       "      <td>582</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>https://t.co/DByWt45HZj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185918</td>\n",
       "      <td>0.192114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>2370803990</td>\n",
       "      <td>Christy Schnicke</td>\n",
       "      <td>ChristySchnicke</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>2360933791</td>\n",
       "      <td>Abbey Pelaez</td>\n",
       "      <td>AbbeyPelaez</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9446 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 name      screen_name  statuses_count  \\\n",
       "0       82118682        davide gazzÃ¨      davidegazze              88   \n",
       "1     1174756808      Carolee Moberly  MoberlycikCarol              19   \n",
       "2      708732794          Julius Kirk    juliuskirkdoq              22   \n",
       "3     2360642101        Magan Skripko     MaganSkripko              47   \n",
       "4     2379608905        Martin Bruley     MartinBruley              34   \n",
       "...          ...                  ...              ...             ...   \n",
       "9441  2363037596          Ula Banegas       UlaBanegas              53   \n",
       "9442  1175035327  Jasmine Finkelstein  FinkelsteinupdJ              22   \n",
       "9443    67631743     TMJ-Morocco Jobs    tmj_mar_jobs1              49   \n",
       "9444  2370803990     Christy Schnicke  ChristySchnicke              64   \n",
       "9445  2360933791         Abbey Pelaez      AbbeyPelaez              35   \n",
       "\n",
       "      followers_count  friends_count  favourites_count  listed_count  \\\n",
       "0                  19             39                 9             0   \n",
       "1                   7            192                 0             0   \n",
       "2                  11            241                 0             0   \n",
       "3                   6             41                 0             0   \n",
       "4                   4             36                 0             0   \n",
       "...               ...            ...               ...           ...   \n",
       "9441                6             36                 0             0   \n",
       "9442                8            194                 0             0   \n",
       "9443              582            494                 0            53   \n",
       "9444               11             43                 0             0   \n",
       "9445                7             42                 0             0   \n",
       "\n",
       "                          url  default_profile  ...  description_90  \\\n",
       "0                         NaN              0.0  ...        0.000000   \n",
       "1                         NaN              1.0  ...        0.000000   \n",
       "2                         NaN              1.0  ...        0.000000   \n",
       "3                         NaN              0.0  ...        0.000000   \n",
       "4                         NaN              0.0  ...        0.000000   \n",
       "...                       ...              ...  ...             ...   \n",
       "9441                      NaN              0.0  ...        0.000000   \n",
       "9442                      NaN              1.0  ...        0.000000   \n",
       "9443  https://t.co/DByWt45HZj              0.0  ...        0.185918   \n",
       "9444                      NaN              0.0  ...        0.000000   \n",
       "9445                      NaN              0.0  ...        0.000000   \n",
       "\n",
       "      description_91 description_92  description_93  description_94  \\\n",
       "0           0.000000            0.0             0.0             0.0   \n",
       "1           0.000000            0.0             0.0             0.0   \n",
       "2           0.000000            0.0             0.0             0.0   \n",
       "3           0.000000            0.0             0.0             0.0   \n",
       "4           0.000000            0.0             0.0             0.0   \n",
       "...              ...            ...             ...             ...   \n",
       "9441        0.000000            0.0             0.0             0.0   \n",
       "9442        0.000000            0.0             0.0             0.0   \n",
       "9443        0.192114            0.0             0.0             0.0   \n",
       "9444        0.000000            0.0             0.0             0.0   \n",
       "9445        0.000000            0.0             0.0             0.0   \n",
       "\n",
       "      description_95  description_96 description_97  description_98  \\\n",
       "0                0.0             0.0            0.0             0.0   \n",
       "1                0.0             0.0            0.0             0.0   \n",
       "2                0.0             0.0            0.0             0.0   \n",
       "3                0.0             0.0            0.0             0.0   \n",
       "4                0.0             0.0            0.0             0.0   \n",
       "...              ...             ...            ...             ...   \n",
       "9441             0.0             0.0            0.0             0.0   \n",
       "9442             0.0             0.0            0.0             0.0   \n",
       "9443             0.0             0.0            0.0             0.0   \n",
       "9444             0.0             0.0            0.0             0.0   \n",
       "9445             0.0             0.0            0.0             0.0   \n",
       "\n",
       "     description_99  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "9441            0.0  \n",
       "9442            0.0  \n",
       "9443            0.0  \n",
       "9444            0.0  \n",
       "9445            0.0  \n",
       "\n",
       "[9446 rows x 233 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6ad70",
   "metadata": {},
   "source": [
    "## Apply same feature engineering on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bae570c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:08.371805Z",
     "start_time": "2022-11-02T09:42:55.319165Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tweet_freq(test, df_tweets)\n",
    "test = tweet_tags_mention(test, df_tweets)\n",
    "test = get_weekend_weekday_frequency(df_tweets, test)\n",
    "test = create_followers_following_ratio(test)\n",
    "test = name_features(test)\n",
    "test = has_url_feature(test)\n",
    "test = clean_texts(test)\n",
    "test = nlp_transform_test(test, tfidf_fit_tweets, tfidf_fit_description)\n",
    "test['has_face'] = test['id'].map(has_face_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39cb1d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:08.376136Z",
     "start_time": "2022-11-02T09:44:08.373113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "print(len(test.columns))\n",
    "print(len(result.columns))\n",
    "\n",
    "for i in result.columns:\n",
    "    if i not in test.columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d477bd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:08.382909Z",
     "start_time": "2022-11-02T09:44:08.377187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1667.000000\n",
       "mean        0.041574\n",
       "std         0.073182\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.057944\n",
       "max         0.602594\n",
       "Name: tweets_99, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tweets_99.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e4e13",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a095632b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:17.249658Z",
     "start_time": "2022-11-02T09:44:08.384272Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"data/twitter_data_train.csv\", index=False)\n",
    "test.to_csv(\"data/twitter_data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48bd5870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:17.261049Z",
     "start_time": "2022-11-02T09:44:17.250580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_90</th>\n",
       "      <th>description_91</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, tweets_66, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 233 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08957afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T09:44:17.271244Z",
     "start_time": "2022-11-02T09:44:17.262490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>description_91</th>\n",
       "      <th>description_92</th>\n",
       "      <th>description_93</th>\n",
       "      <th>description_94</th>\n",
       "      <th>description_95</th>\n",
       "      <th>description_96</th>\n",
       "      <th>description_97</th>\n",
       "      <th>description_98</th>\n",
       "      <th>description_99</th>\n",
       "      <th>has_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, screen_name, statuses_count, followers_count, friends_count, favourites_count, listed_count, url, default_profile, default_profile_image, geo_enabled, profile_image_url, profile_use_background_image, profile_background_tile, protected, verified, description, account_type, tweets_list, tweet_frequency, number_of_tags, number_of_mentions, tweet_weekend_frequency, tweet_weekday_frequency, following_to_followers_ratio, username_length, screen_name_length, username_spec_char_count, screen_name_spec_char_count, has_url, tweets_list_processed, description_processed, tweets_0, tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, tweets_17, tweets_18, tweets_19, tweets_20, tweets_21, tweets_22, tweets_23, tweets_24, tweets_25, tweets_26, tweets_27, tweets_28, tweets_29, tweets_30, tweets_31, tweets_32, tweets_33, tweets_34, tweets_35, tweets_36, tweets_37, tweets_38, tweets_39, tweets_40, tweets_41, tweets_42, tweets_43, tweets_44, tweets_45, tweets_46, tweets_47, tweets_48, tweets_49, tweets_50, tweets_51, tweets_52, tweets_53, tweets_54, tweets_55, tweets_56, tweets_57, tweets_58, tweets_59, tweets_60, tweets_61, tweets_62, tweets_63, tweets_64, tweets_65, tweets_66, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 234 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.id==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "b14d2bd7895077ad303f266db7ad1f8a11e285bbfcdfa868008aad211f623e81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
