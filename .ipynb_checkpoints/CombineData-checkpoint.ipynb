{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine 2015 (df_bandy) and 2017 (df_valentin) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/ivankoh/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/1D/NUS Y3S1/BT4012/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valentin = pd.read_excel(base + \"data.xlsx\")\n",
    "df_valentin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bandy = pd.read_csv(base + \"/all_users_2015.csv\")\n",
    "df_bandy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing which columns to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with all the same values or null\n",
    "to_remove_valentin = []\n",
    "to_remove_bandy = []\n",
    "\n",
    "def remove_columns(df,to_remove_list):\n",
    "  for i in df: \n",
    "    if len(set(df[i])) == 1 or all(pd.isnull(df[i])):\n",
    "      to_remove_list.append(i)\n",
    "      print(i)\n",
    "\n",
    "print(\"Valentin_df: Columns with the same values in all of its rows are:\")\n",
    "remove_columns(df_valentin,to_remove_valentin)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"Bandy_df: Columns with the same values in all of its rows are:\")\n",
    "\n",
    "remove_columns(df_bandy,to_remove_bandy)\n",
    "\n",
    "\n",
    "# remove_list.append('country_displayable_name')\n",
    "# print('country_displayable_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'protected' and 'verified from to_remove_list for 2015 dataset\n",
    "# Even though all values for the above columns are null in 2015 dataset, they are not null in 2017 dataset\n",
    "# A null entry hence might represent an absence of that attribute, meaning that all accounts in 2015 data are not protected and not verified\n",
    "to_remove_bandy.remove('protected')\n",
    "to_remove_bandy.remove('verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant columns\n",
    "# Columns 'test_set_1' and'test_set_2' were used for the previous researcher's own testing\n",
    "to_remove_valentin.extend(['test_set_1', 'test_set_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 14368 rows, only 1 row has 'is_translator' == 1\n",
    "# Remove 'is_translator' due to imbalanced distribution of positive instances and lack of further information from data source\n",
    "display(df_valentin.loc[df_valentin['is_translator'] == 1,:])\n",
    "to_remove_valentin.extend(['is_translator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'timestamp' and 'created_at' seem to represent the same date but different time in different formats.\n",
    "# Keep 'created_at' to standardise with df_bandy, remove 'timestamp' and 'crawled_at' due to missing data\n",
    "display(df_valentin.loc[:,['timestamp','created_at','crawled_at']])\n",
    "print(\"Number of missing entries in created_at column:\", len(df_valentin[pd.isnull(df_valentin['created_at'])]))\n",
    "print(\"Number of missing entries in timestamp column:\", len(df_valentin[pd.isnull(df_valentin['timestamp'])]))\n",
    "print(\"Number of missing entries in crawled_at column:\", len(df_valentin[pd.isnull(df_valentin['crawled_at'])]))\n",
    "\n",
    "to_remove_valentin.extend(['timestamp','crawled_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dataset in 2015 dataset as it is no longer relevant since the data has been labelled\n",
    "print(\"Unique values in dataset column\", set(df_bandy['dataset'].values))\n",
    "to_remove_bandy.extend(['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping columns, both dataset have the same number of columns\n",
    "df_valentin = df_valentin.drop(to_remove_valentin, axis = 1)\n",
    "print(df_valentin.shape)\n",
    "\n",
    "df_bandy = df_bandy.drop(to_remove_bandy, axis = 1)\n",
    "print(df_bandy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All colmns in 2015 and 2017 dataset have the same name, but might not be in the same order\n",
    "print(set(df_bandy.columns) == set(df_valentin.columns))\n",
    "\n",
    "# Rearrange 2015 dataset columns to be the same as that of 2017 for merging\n",
    "cols_list = df_valentin.columns.tolist()\n",
    "df_bandy = df_bandy[cols_list]\n",
    "\n",
    "# All colmns in 2015 and 2017 dataset have the same name and are in the same order, ready for merge\n",
    "print(list(df_bandy.columns) == list(df_valentin.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both dataset and remove duplicated ids\n",
    "combined_df = pd.concat([df_bandy, df_valentin], axis=0, ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset=['id'])\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows that profile picture cannot be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that profile pic cannot be scraped\n",
    "with open('data/failed_id_batch1.json') as data:\n",
    "    failed_id_1 = json.load(data)\n",
    "with open('data/failed_id_batch2.json') as data:\n",
    "    failed_id_2 = json.load(data)\n",
    "failed_id = failed_id_1 + failed_id_2\n",
    "failed_id = list(set(failed_id)) # Remove duplicated id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = combined_df\n",
    "index_list = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    if row['id'] in failed_id:\n",
    "        index_list.append(index)\n",
    "\n",
    "unique_index_list = list(set(index_list)) # Remove duplicated indexes\n",
    "cleaned_df.drop(unique_index_list,inplace = True)\n",
    "cleaned_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(base + 'combined_twitter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (bt4012)",
   "language": "python",
   "name": "bt4012"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "77238a471535228e8cd55a3ca9e771a69c6c0bc66c44a56c972f9554a4042742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
