{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine 2015 and 2017 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/bandy/Downloads/BT4012/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14368, 43)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = pd.read_excel(base + \"data.xlsx\")\n",
    "df_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'screen_name', 'statuses_count', 'followers_count',\n",
       "       'friends_count', 'favourites_count', 'listed_count', 'created_at',\n",
       "       'url', 'lang', 'time_zone', 'location', 'default_profile',\n",
       "       'default_profile_image', 'geo_enabled', 'profile_image_url',\n",
       "       'profile_banner_url', 'profile_use_background_image',\n",
       "       'profile_background_image_url_https', 'profile_text_color',\n",
       "       'profile_image_url_https', 'profile_sidebar_border_color',\n",
       "       'profile_background_tile', 'profile_sidebar_fill_color',\n",
       "       'profile_background_image_url', 'profile_background_color',\n",
       "       'profile_link_color', 'utc_offset', 'protected', 'verified',\n",
       "       'description', 'updated', 'dataset', 'account_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015 = pd.read_csv(base + \"all_users_2015.csv\")\n",
    "df_2015.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing which columns to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 df: Columns with the same values in all of its rows are:\n",
      "follow_request_sent\n",
      "notifications\n",
      "contributors_enabled\n",
      "following\n",
      "--------------------------------------------------------------\n",
      "2015 df: Columns with the same values in all of its rows are:\n",
      "protected\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "#Remove columns with all the same values or null\n",
    "to_remove_2017 = []\n",
    "to_remove_2015 = []\n",
    "\n",
    "def remove_columns(df, to_remove_list):\n",
    "  for i in df: \n",
    "    if len(set(df[i])) == 1 or all(pd.isnull(df[i])):\n",
    "      to_remove_list.append(i)\n",
    "      print(i)\n",
    "\n",
    "print(\"2017 df: Columns with the same values in all of its rows are:\")\n",
    "remove_columns(df_2017, to_remove_2017)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"2015 df: Columns with the same values in all of its rows are:\")\n",
    "\n",
    "remove_columns(df_2015, to_remove_2015)\n",
    "\n",
    "\n",
    "# remove_list.append('country_displayable_name')\n",
    "# print('country_displayable_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'protected' and 'verified from to_remove_list for 2015 dataset\n",
    "# Even though all values for the above columns are null in 2015 dataset, they are no null in 2017 dataset\n",
    "# A null entry hence might represent an absence of that attribute, meaning that all accounts in 2015 data are not protected and not verified\n",
    "to_remove_2015.remove('protected')\n",
    "to_remove_2015.remove('verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant columns\n",
    "# Columns 'test_set_1' and'test_set_2' were used for the previous researcher's own testing\n",
    "to_remove_2017.extend(['test_set_1', 'test_set_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>description</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>following</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "      <th>test_set_1</th>\n",
       "      <th>test_set_2</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>110928853</td>\n",
       "      <td>Ayumi</td>\n",
       "      <td>Ayu</td>\n",
       "      <td>41271</td>\n",
       "      <td>15171</td>\n",
       "      <td>210</td>\n",
       "      <td>7721</td>\n",
       "      <td>174</td>\n",
       "      <td>http://t.co/XQBf9jn3u8</td>\n",
       "      <td>ja</td>\n",
       "      <td>...</td>\n",
       "      <td>[è‹±èªžï¼‹æ—¥æœ¬èªž] åˆ_x009d_ã‚_x0081_ã_x0081...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Feb 03 07:01:41 +0000 2010</td>\n",
       "      <td>2010-02-03 08:01:41</td>\n",
       "      <td>2015-05-02 06:34:44</td>\n",
       "      <td>2016-03-15 15:54:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   name screen_name  statuses_count  followers_count  \\\n",
       "163  110928853  Ayumi         Ayu           41271            15171   \n",
       "\n",
       "     friends_count  favourites_count  listed_count                     url  \\\n",
       "163            210              7721           174  http://t.co/XQBf9jn3u8   \n",
       "\n",
       "    lang  ...                                        description  \\\n",
       "163   ja  ...  [è‹±èªžï¼‹æ—¥æœ¬èªž] åˆ_x009d_ã‚_x0081_ã_x0081...   \n",
       "\n",
       "    contributors_enabled  following                      created_at  \\\n",
       "163                  NaN        NaN  Wed Feb 03 07:01:41 +0000 2010   \n",
       "\n",
       "              timestamp          crawled_at             updated  test_set_1  \\\n",
       "163 2010-02-03 08:01:41 2015-05-02 06:34:44 2016-03-15 15:54:37         0.0   \n",
       "\n",
       "    test_set_2 account_type  \n",
       "163        0.0         real  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Out of 14368 rows, only 1 row has 'is_translator' == 1\n",
    "# Remove 'is_translator' due to imbalanced distribution of positive instances and lack of further information from data source\n",
    "display(df_2017.loc[df_2017['is_translator'] == 1,:])\n",
    "to_remove_2017.extend(['is_translator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>created_at</th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-11 13:20:35</td>\n",
       "      <td>Tue Jun 11 11:20:35 +0000 2013</td>\n",
       "      <td>2015-05-02 06:41:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-13 12:37:57</td>\n",
       "      <td>Tue May 13 10:37:57 +0000 2014</td>\n",
       "      <td>2015-05-01 17:20:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-05 01:30:37</td>\n",
       "      <td>Wed May 04 23:30:37 +0000 2011</td>\n",
       "      <td>2015-05-01 18:48:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-09-17 16:02:10</td>\n",
       "      <td>Fri Sep 17 14:02:10 +0000 2010</td>\n",
       "      <td>2015-05-01 13:55:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-06 05:10:49</td>\n",
       "      <td>Fri Feb 06 04:10:49 +0000 2015</td>\n",
       "      <td>2015-05-02 01:17:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14363</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Tue Apr 30 08:23:57 +0000 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14364</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Tue Apr 30 08:34:49 +0000 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14365</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Tue Apr 30 09:21:12 +0000 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14366</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Tue Apr 30 11:25:11 +0000 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14367</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Tue Apr 30 12:47:51 +0000 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp                      created_at          crawled_at\n",
       "0     2013-06-11 13:20:35  Tue Jun 11 11:20:35 +0000 2013 2015-05-02 06:41:46\n",
       "1     2014-05-13 12:37:57  Tue May 13 10:37:57 +0000 2014 2015-05-01 17:20:27\n",
       "2     2011-05-05 01:30:37  Wed May 04 23:30:37 +0000 2011 2015-05-01 18:48:28\n",
       "3     2010-09-17 16:02:10  Fri Sep 17 14:02:10 +0000 2010 2015-05-01 13:55:16\n",
       "4     2015-02-06 05:10:49  Fri Feb 06 04:10:49 +0000 2015 2015-05-02 01:17:32\n",
       "...                   ...                             ...                 ...\n",
       "14363                 NaT  Tue Apr 30 08:23:57 +0000 2013                 NaT\n",
       "14364                 NaT  Tue Apr 30 08:34:49 +0000 2013                 NaT\n",
       "14365                 NaT  Tue Apr 30 09:21:12 +0000 2013                 NaT\n",
       "14366                 NaT  Tue Apr 30 11:25:11 +0000 2013                 NaT\n",
       "14367                 NaT  Tue Apr 30 12:47:51 +0000 2013                 NaT\n",
       "\n",
       "[14368 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing entries in created_at column: 0\n",
      "Number of missing entries in timestamp column: 3351\n",
      "Number of missing entries in crawled_at column: 3351\n"
     ]
    }
   ],
   "source": [
    "# 'timestamp' and 'created_at' seem to represent the same date but different time in different formats.\n",
    "# Keep 'created_at' to standardise with df_2015, remove 'timestamp' and 'crawled_at' due to missing data\n",
    "display(df_2017.loc[:,['timestamp','created_at','crawled_at']])\n",
    "print(\"Number of missing entries in created_at column:\", len(df_2017[pd.isnull(df_2017['created_at'])]))\n",
    "print(\"Number of missing entries in timestamp column:\", len(df_2017[pd.isnull(df_2017['timestamp'])]))\n",
    "print(\"Number of missing entries in crawled_at column:\", len(df_2017[pd.isnull(df_2017['crawled_at'])]))\n",
    "\n",
    "to_remove_2017.extend(['timestamp','crawled_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in dataset column {'TWT', 'E13', 'INT', 'TFP', 'FSF'}\n"
     ]
    }
   ],
   "source": [
    "# Remove dataset in 2015 dataset as it is no longer relevant since the data has been labelled\n",
    "print(\"Unique values in dataset column\", set(df_2015['dataset'].values))\n",
    "to_remove_2015.extend(['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14368, 34)\n",
      "(5301, 34)\n"
     ]
    }
   ],
   "source": [
    "# After dropping columns, both dataset have the same number of columns\n",
    "df_2017 = df_2017.drop(to_remove_2017, axis = 1)\n",
    "print(df_2017.shape)\n",
    "\n",
    "df_2015 = df_2015.drop(to_remove_2015, axis = 1)\n",
    "print(df_2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# All colmns in 2015 and 2017 dataset have the same name, but might not be in the same order\n",
    "print(set(df_2015.columns) == set(df_2017.columns))\n",
    "\n",
    "# Rearrange 2015 dataset columns to be the same as that of 2017 for merging\n",
    "cols_list = df_2017.columns.tolist()\n",
    "df_2015 = df_2015[cols_list]\n",
    "\n",
    "# All colmns in 2015 and 2017 dataset have the same name and are in the same order, ready for merge\n",
    "print(list(df_2015.columns) == list(df_2017.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16318, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine both dataset and remove duplicated ids\n",
    "combined_df = pd.concat([df_2015, df_2017], axis=0, ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset=['id'])\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows that profile picture cannot be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that profile pic cannot be scraped\n",
    "with open(base + 'failed_id_new_batch_2015.json') as data:\n",
    "    failed_id_1 = json.load(data)\n",
    "with open(base + 'failed_id_new_batch_2017.json') as data:\n",
    "    failed_id_2 = json.load(data)\n",
    "failed_id = failed_id_1 + failed_id_2\n",
    "failed_id = list(set(failed_id)) # Remove duplicated id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11113, 34)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = combined_df\n",
    "index_list = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    if row['id'] in failed_id:\n",
    "        index_list.append(index)\n",
    "\n",
    "unique_index_list = list(set(index_list)) # Remove duplicated indexes\n",
    "cleaned_df.drop(unique_index_list,inplace = True)\n",
    "cleaned_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(base + 'combined_twitter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b14d2bd7895077ad303f266db7ad1f8a11e285bbfcdfa868008aad211f623e81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
